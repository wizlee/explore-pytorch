{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"------------------------------------------------------------------------\n\n# Summary\n\n------------------------------------------------------------------------\n\n> Expand to see summary and details","metadata":{}},{"cell_type":"markdown","source":"## Overview and Explanation\n\n1.  This notebook reuses a lot of the [original transfer learning\n    notebook](https://colab.research.google.com/drive/187Z04CNQBVV3jmCdA2sSbMTs9BB40qh_#scrollTo=QgZD08Q-YXXH)\n    -   Here the focus is on building the new custom model using the\n        CovidNet-CT database.\n2.  The [`Setup Kaggle`](#scrollTo=wMQLloEgzPol) section:\n    -   is not longer needed for notebook running in kaggle. Remained\n        here for references only\n    -   is where the dataset is being acquired.\n    -   Explanation of various phases in the [CovidNet-CT ML\n        code](https://github.com/haydengunraj/COVIDNet-CT/blob/02009821b9d063d01994cb70e61b8def0af275ab/run_covidnet_ct.py#L415):\n        -   train phase is train phase\n        -   test phase is validation phase\n        -   infer phase is test phase\n3.  The [`Data Preprocessing`](#scrollTo=JjsNA--kG9CV) section:\n    -   refers to the way [CovidNet-CT preprocess its\n        data](https://github.com/haydengunraj/COVIDNet-CT/blob/d1c6be5202a78d5f8802e40ff6b5b9d57189c797/dataset.py#L72)\n    -   CovidNet-CT uses TensorFlow while this notebook adapts the code\n        to use PyTorch\n    -   Two highlights\n        -   input shape is (512, 512, 3) instead of the (224, 224, 3)\n            used by the imagenet model\n        -   the image is cropped to the bounding box provided with the\n            dataset before resize to 512x512\n4.  The [`Training & Validation`](#scrollTo=YqGCBwYdasI_) section:\n    -   refers to [how CovidNet-CT\n        trains](https://github.com/haydengunraj/COVIDNet-CT/blob/02009821b9d063d01994cb70e61b8def0af275ab/run_covidnet_ct.py#L174)\n    -   This part is almost identical to the original transfer learning\n        model notebook.","metadata":{}},{"cell_type":"markdown","source":"------------------------------------------------------------------------\n\n# Import and Deterministic Setup\n\n------------------------------------------------------------------------\n\nAll modules will be imported here including modules used in the\n[Playground](#playground) section","metadata":{}},{"cell_type":"code","source":"from __future__ import print_function, division\nimport os\n%env CUDA_LAUNCH_BLOCKING=1\nimport random\nimport numpy as np\nimport torch\n\nfrom os import path\nimport math\nimport sys\n\nfrom torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split #, StratifiedShuffleSplit\n\nimport torchvision\nfrom torchvision import models, transforms #, datasets\nimport matplotlib.pyplot as plt\n\nfrom torch import optim\nfrom torch.nn import Module, Sequential, LeakyReLU, Conv2d, BatchNorm2d, AvgPool2d, MaxPool2d, AdaptiveAvgPool2d, Linear, CrossEntropyLoss\nfrom torch.optim import lr_scheduler\nimport time\nimport torch.nn.functional as F\n\nimport gc\nimport pandas as pd\nimport enum\nfrom enum import Enum\n\n# ensure reproducibility across different executions\n# https://pytorch.org/docs/stable/notes/randomness.html\n# https://www.kaggle.com/mlwhiz/third-place-model-for-toxic-comments-in-pytorch\n# https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html\nSEED = 18\ndef seed_everything(seed=18):\n    random.seed(seed)\n    %env PYTHONHASHSEED=$seed\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.deterministic = True\n#torch.set_deterministic(True)\ntorch.use_deterministic_algorithms(True)\n%env CUBLAS_WORKSPACE_CONFIG=:4096:8\n%env PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512\n        \n# https://www.kaggle.com/code/manabendrarout/vision-transformer-vit-pytorch-on-tpus-train/notebook\ndef is_tpu_avail():\n    TPU_DETECTED = False\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        TPU_DETECTED = True\n    except:\n        pass\n\n    return TPU_DETECTED\n\n\ndef is_gpu_avail():\n    GPU_DETECTED = False\n    try:\n        GPU_DETECTED = torch.cuda.is_available()\n    except:\n        pass\n\n    return GPU_DETECTED","metadata":{"outputId":"9f9e4454-b1ca-47d8-b3c0-873d01043bf2","execution":{"iopub.status.busy":"2023-02-18T02:52:54.317411Z","iopub.execute_input":"2023-02-18T02:52:54.317884Z","iopub.status.idle":"2023-02-18T02:52:57.103579Z","shell.execute_reply.started":"2023-02-18T02:52:54.317803Z","shell.execute_reply":"2023-02-18T02:52:57.102484Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"env: CUDA_LAUNCH_BLOCKING=1\nenv: CUBLAS_WORKSPACE_CONFIG=:4096:8\nenv: PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512\n","output_type":"stream"}]},{"cell_type":"markdown","source":"------------------------------------------------------------------------\n\n# Data Preprocessing\n\n------------------------------------------------------------------------\n\n-   [how torch dataset is loaded](https://github.com/pytorch/vision/blob/main/torchvision/datasets/folder.py#L45)\n-   [example custom model and custom dataset](https://github.com/ArnaudMallet/Plant_Patho/blob/master/Plant_Patho_4.ipynb)\n    -   [pytorch thread](https://discuss.pytorch.org/t/how-to-load-data-from-a-csv/58315/10) that mentioned this example\n-   [A well explained custom dataset](https://github.com/utkuozbulak/pytorch-custom-dataset-examples)","metadata":{}},{"cell_type":"markdown","source":"## Custom Dataset class to load CovidNet data\n\n- Various references used: \n  - https://colab.research.google.com/drive/187Z04CNQBVV3jmCdA2sSbMTs9BB40qh\\_#scrollTo=H9doKmx1TXK1 \n  - https://drive.google.com/drive/folders/13PnDpSYUaVaKHjXjUK6bwWvJddDfbRad \n  - https://github.com/haydengunraj/COVIDNet-CT/blob/d1c6be5202a78d5f8802e40ff6b5b9d57189c797/dataset.py#L72 \n  - https://github.com/haydengunraj/COVIDNet-CT/blob/master/docs/dataset.md \n  - https://www.kaggle.com/datasets/hgunraj/covidxct?select=metadata.csv \n  - https://stackoverflow.com/questions/50544730/how-do-i-split-a-custom-dataset-into-training-and-test-datasets/50544887#50544887 \n  - https://github.com/pytorch/vision/blob/main/torchvision/datasets/folder.py \n  - https://github.com/pytorch/vision/blob/d4a03fc02d0566ec97341046de58160370a35bd2/torchvision/datasets/vision.py#L10","metadata":{}},{"cell_type":"code","source":"class CovidNetDataset(Dataset):\n    def __init__(self, img_dir, split_files, limit_size = 0, transform = None):\n        # don't seem to need the csv file\n        # self.df = pd.read_csv(csv_path)\n        # _, self.class_to_idx  = self.find_classes(csv_path);\n\n        self.img_dir = img_dir\n        self.split_files = split_files\n        \n        self.size = 0\n        self.limit_size = limit_size\n        self.imgs, self.targets, self.bboxes = self.get_all_split_file_data()\n        self.stradify_removal_based_on_limit()\n        # self.imgs = [entry.name for entry in os.scandir(img_dir) if entry.is_file()]\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.imgs)\n\n    def __getitem__(self, index):\n        # filename = self.df[index, \"FILENAME\"]\n        # label = self.class_to_idx [self.df[index, \"LABEL\"]]\n        # image = Image.open(os.path.join(self.img_dir, filename))\n\n        label = self.targets[index]\n        with open(self.imgs[index], \"rb\") as f:\n            image = Image.open(f)\n            image = image.crop(self.bboxes[index])\n            image = image.copy()\n\n        if self.transform is not None:\n            image = self.transform(image)\n    \n\n        return image, label\n\n    # from https://github.com/pytorch/vision/blob/main/torchvision/datasets/folder.py#L36\n    def find_classes(self, csv_path=None):\n        \"\"\"Returns class name array and class_to_idx.\n        See :class:`CovidNetDataset` for details.\n        \"\"\"\n        # class_col = \"finding\"\n        # classes = sorted(self.df[class_col].unique())\n        # if not classes:\n        #     raise FileNotFoundError(f\"Couldn't find any class from '{class_col}' column in {csv_path}.\")\n\n        # hard code classes as the order are not alphabetic\n        classes = ['Normal', 'Pneumonia', 'COVID-19']\n\n        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n        return classes, class_to_idx\n\n    def get_all_split_file_data(self):\n        files, classes, bboxes = [], [], []\n        for split_file in self.split_files:\n            f, cls, bb = self.get_data_from_split_file(split_file)\n            files.extend(f)\n            classes.extend(cls)\n            bboxes.extend(bb)\n        return files, classes, bboxes\n\n    # from https://github.com/haydengunraj/COVIDNet-CT/blob/d1c6be5202a78d5f8802e40ff6b5b9d57189c797/dataset.py#L108\n    def get_data_from_split_file(self, split_file):\n        \"\"\"Gets image filenames, classes and bboxes\"\"\"\n        files, classes, bboxes = [], [], []\n        with open(split_file, 'r') as f:\n            for line in f.readlines():\n                fname, cls, xmin, ymin, xmax, ymax = line.strip('\\n').split()\n                files.append(path.join(self.img_dir, fname))\n                classes.append(int(cls))\n                bboxes.append([int(xmin), int(ymin), int(xmax), int(ymax)])\n                self.size += 1\n        return files, classes, bboxes\n    \n    '''Try to do stratified removal based on limit count if it is specified'''\n    def stradify_removal_based_on_limit(self):\n        _, class_to_idx = self.find_classes()\n        MIN_SIZE = len(class_to_idx) * 10 # allow for some buffer to work with\n        if self.limit_size <= 0 or self.limit_size <= MIN_SIZE or self.limit_size >= self.size:\n            return\n        \n        total_remove_count = self.size - self.limit_size\n        occurrence = {idx: self.targets.count(idx) for _, idx in class_to_idx.items()}\n        target_remove_count = {idx: 0 for _, idx in class_to_idx.items()}\n        for idx, count in occurrence.items():\n            target_remove_count[idx] = math.floor(total_remove_count * count / self.size)\n        \n        print(occurrence)\n        print(target_remove_count)\n        \n        for i in reversed(range(len(self.targets))):\n            idx = self.targets[i]\n            if target_remove_count[idx] > 0:\n                del self.targets[i]\n                del self.imgs[i]\n                del self.bboxes[i]\n                target_remove_count[idx] -= 1\n                self.size -= 1","metadata":{"execution":{"iopub.status.busy":"2023-02-18T02:52:57.109021Z","iopub.execute_input":"2023-02-18T02:52:57.111619Z","iopub.status.idle":"2023-02-18T02:52:57.140877Z","shell.execute_reply.started":"2023-02-18T02:52:57.111579Z","shell.execute_reply":"2023-02-18T02:52:57.138255Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Spliting dataset into train, val, test\n\n-   [SO QA on spliting using sklearn](https://datascience.stackexchange.com/questions/15135/train-test-validation-set-splitting-in-sklearn)\n    -   [Train test split example](https://stackoverflow.com/questions/38250710/how-to-split-data-into-3-sets-train-validation-and-test)\n    -   [train test split example with indices](https://stackoverflow.com/questions/31521170/scikit-learn-train-test-split-with-indices)\n-   [Pytorch stratified split example](https://discuss.pytorch.org/t/how-to-do-a-stratified-split/62290)\n-   [sklearn StratifiedShuffleSplit doc](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html)\n-   [StratifiedShuffleSplit example](https://stackoverflow.com/questions/29438265/stratified-train-test-split-in-scikit-learn)\n-   [another StratifiedShuffleSplit example](https://stackoverflow.com/questions/40829137/stratified-train-validation-test-split-in-scikit-learn)","metadata":{}},{"cell_type":"code","source":"# Specify all the filepath of the dataset\nCURR_DIR = \"/kaggle/working\"\nDATA_DIR = \"/kaggle/input/covidxct\"\ndirs = [entry.name for entry in os.scandir(DATA_DIR) if entry.is_dir()]\nassert len(dirs) == 1 # expects to only have 1 folder that contains all the images\n\nDATASET_DIR = path.join(DATA_DIR, dirs[0])\nMETADATA_CSV = path.join(DATA_DIR, \"metadata.csv\")\n\nDATASET_NAME = \"COVIDx_CT-3A\"\nTRAIN_SPLIT_FILE = path.join(DATA_DIR, f\"train_{DATASET_NAME}.txt\")\nVAL_SPLIT_FILE = path.join(DATA_DIR, f\"val_{DATASET_NAME}.txt\")\nTEST_SPLIT_FILE = path.join(DATA_DIR, f\"test_{DATASET_NAME}.txt\")\nSPLIT_FILES = [TRAIN_SPLIT_FILE, VAL_SPLIT_FILE, TEST_SPLIT_FILE]\n\nMAX_COUNT = 10000\nfull_dataset = CovidNetDataset(DATASET_DIR, SPLIT_FILES, MAX_COUNT)\nfull_data_len = len(full_dataset)\nprint(f\"Length of full dataset: {full_data_len}\")\n\n# # Defines ratios, w.r.t. whole dataset.\nratio_train = 0.8\nratio_val = 0.1\nratio_test = 0.1\ndummy_X = np.zeros(full_data_len)\nindexes = np.arange(full_data_len)\n\n# Produces test split. Uses train_test_split instead of StratifiedShuffleSplit to get x_remaining & y_remaining\n# to be used in the next step. \n# Note that an additional indexes array is provided\nx_remaining, _, y_remaining, _, temp_train_index, test_index = train_test_split(\n    dummy_X, full_dataset.targets, indexes, test_size=ratio_test, stratify=full_dataset.targets, random_state=SEED)\n\n# Adjusts val ratio, w.r.t. remaining dataset.\nratio_remaining = 1 - ratio_test\nratio_val_adjusted = ratio_val / ratio_remaining\n\n# Produces train and val splits.\n_, _, _, _, train_index, val_index = train_test_split(\n    x_remaining, y_remaining, temp_train_index, test_size=ratio_val_adjusted, stratify=y_remaining, random_state=SEED)\n\n# dataset size\ntrain_data_size = len(train_index)\nvalid_data_size = len(val_index)\ntest_data_size = len(test_index)\n\nprint(f\"First 10 train_index: {train_index[:10]}\")\nprint(f\"length of train_index: {train_data_size}\\n\")\nprint(f\"First 10 val_index: {val_index[:10]}\")\nprint(f\"length of val_index: {valid_data_size}\\n\")\nprint(f\"First 10 test_index: {test_index[:10]}\")\nprint(f\"length of test_index: {test_data_size}\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-02-18T02:52:57.146164Z","iopub.execute_input":"2023-02-18T02:52:57.149184Z","iopub.status.idle":"2023-02-18T02:53:00.101580Z","shell.execute_reply.started":"2023-02-18T02:52:57.149147Z","shell.execute_reply":"2023-02-18T02:53:00.100504Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"{0: 71488, 1: 42943, 2: 310593}\n{0: 69806, 1: 41932, 2: 303285}\nLength of full dataset: 10001\nFirst 10 train_index: [6373 6939 9338  105 7573 4773 9125 4210 4499 1754]\nlength of train_index: 7999\n\nFirst 10 val_index: [6942 5767  536 6017 6502 1373 8798 3052 4665 9964]\nlength of val_index: 1001\n\nFirst 10 test_index: [9022 9017 9868 1724  795 4754 4568 1985 9612 9534]\nlength of test_index: 1001\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Applying transforms to dataset","metadata":{}},{"cell_type":"markdown","source":"### Define a wrapper dataset\n\n- This is to have the flexibility of applying different transforms to each of the splitted dataset \n- References \n    - [wrapper dataset source](https://stackoverflow.com/questions/57539567/augmenting-only-the-training-set-in-k-folds-cross-validation/57539790#57539790)\n    - [pytorch dataset lazy loading idea](https://discuss.pytorch.org/t/split-dataset-into-training-and-validation-without-applying-training-transform/115429/3)\n    - [individual transform using torchdata](https://stackoverflow.com/questions/61811946/train-valid-test-split-for-custom-dataset-using-pytorch-and-torchvision)","metadata":{}},{"cell_type":"code","source":"class WrapperDataset:\n    def __init__(self, dataset, transform=None, target_transform=None):\n        self.dataset = dataset\n        self.transform = transform\n        self.target_transform = target_transform\n\n    def __getitem__(self, index):\n        image, label = self.dataset[index]\n        if self.transform is not None:\n            image = self.transform(image)\n        if self.target_transform is not None:\n            label = self.target_transform(label)\n        return image, label\n\n    def __len__(self):\n        return len(self.dataset)","metadata":{"execution":{"iopub.status.busy":"2023-02-18T02:53:00.107243Z","iopub.execute_input":"2023-02-18T02:53:00.109761Z","iopub.status.idle":"2023-02-18T02:53:00.120300Z","shell.execute_reply.started":"2023-02-18T02:53:00.109720Z","shell.execute_reply":"2023-02-18T02:53:00.119143Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Defining the transforms\n\n- References for mean and std of images \n    - [pytorch forum thread](https://discuss.pytorch.org/t/normalization-in-the-mnist-example/457/27?u=kharshit) \n    - [how the mean and std of imagenet transform being calculated](https://stackoverflow.com/questions/57532661/how-do-they-know-mean-and-std-the-input-value-of-transforms-normalize?noredirect=1&lq=1) \n    - [another similar SO question](https://stackoverflow.com/questions/58151507/why-pytorch-officially-use-mean-0-485-0-456-0-406-and-std-0-229-0-224-0-2) \n    - [grayscale vs RGB images in ML training](https://towardsdatascience.com/transfer-learning-on-greyscale-images-how-to-fine-tune-pretrained-models-on-black-and-white-9a5150755c7a) \n    - Bounding box causing issue when batching as stacking don’t work with\n    different size \n        - [easiest solution is to use tuple as the parameter](https://discuss.pytorch.org/t/runtimeerror-stack-expects-each-tensor-to-be-equal-size-but-got-3-224-224-at-entry-0-and-3-224-336-at-entry-3/87211/10) when calling `transform.resize()` \n        - [another solution is to override `collate_fn()`](https://discuss.pytorch.org/t/dataloader-gives-stack-expects-each-tensor-to-be-equal-size-due-to-different-image-has-different-objects-number/91941) when contructing `Dataloader`","metadata":{}},{"cell_type":"code","source":"covidnet_std_transform = transforms.Compose([\n    transforms.Grayscale(num_output_channels=3),\n    transforms.Resize((512, 512)), # this is important or else batching will have error due to bbox\n    transforms.ToTensor(),\n    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)) # POTENTIAL_FINE_TUNE\n])\n\ncovidnet_train_transform = transforms.Compose([\n    transforms.RandomChoice(transforms=[\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.RandomRotation(10),\n        transforms.ColorJitter(brightness=.3, hue=.3),\n        transforms.RandomPerspective(distortion_scale=0.4),\n        transforms.RandomAffine(degrees=(0, 0), translate=(0.05, 0.1), scale=(0.85, 0.95))])\n    ])\n\nimage_transforms = {\n    'train': transforms.Compose([\n        covidnet_train_transform,\n        covidnet_std_transform\n    ]),\n    'val': transforms.Compose([\n        covidnet_std_transform\n    ]),\n    'test': transforms.Compose([\n        covidnet_std_transform\n    ]),\n    'playground': transforms.Compose([\n        covidnet_train_transform,\n        covidnet_std_transform\n    ])\n}","metadata":{"execution":{"iopub.status.busy":"2023-02-18T02:53:00.121719Z","iopub.execute_input":"2023-02-18T02:53:00.122496Z","iopub.status.idle":"2023-02-18T02:53:00.135517Z","shell.execute_reply.started":"2023-02-18T02:53:00.122458Z","shell.execute_reply":"2023-02-18T02:53:00.134266Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### Creating the Dataset Loader","metadata":{}},{"cell_type":"code","source":"seed_everything(SEED)\nBATCH_SIZE = 16\n\ntrain_sampler = SubsetRandomSampler(train_index)\nval_sampler = SubsetRandomSampler(val_index)\ntest_sampler = SubsetRandomSampler(test_index)\n\ntrain_loader = DataLoader(WrapperDataset(full_dataset, image_transforms['train']), batch_size=BATCH_SIZE, sampler=train_sampler)\nval_loader = DataLoader(WrapperDataset(full_dataset, image_transforms['val']), batch_size=BATCH_SIZE, sampler=val_sampler)\ntest_loader = DataLoader(WrapperDataset(full_dataset, image_transforms['test']), batch_size=BATCH_SIZE, sampler=test_sampler)\n\nclass_names, class_to_idx = full_dataset.find_classes()\nprint(class_names)\nprint(class_to_idx)\n\nif is_tpu_avail():\n    device = 'TPU'\nelif is_gpu_avail():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\n    \nprint(f'Using device: {device}')\nprint(f'train size:{train_data_size}; validation size:{valid_data_size}; test size:{test_data_size}')","metadata":{"execution":{"iopub.status.busy":"2023-02-18T02:53:00.136801Z","iopub.execute_input":"2023-02-18T02:53:00.137561Z","iopub.status.idle":"2023-02-18T02:53:00.212066Z","shell.execute_reply.started":"2023-02-18T02:53:00.137527Z","shell.execute_reply":"2023-02-18T02:53:00.210842Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"env: PYTHONHASHSEED=18\n['Normal', 'Pneumonia', 'COVID-19']\n{'Normal': 0, 'Pneumonia': 1, 'COVID-19': 2}\nUsing device: cuda\ntrain size:7999; validation size:1001; test size:1001\n","output_type":"stream"}]},{"cell_type":"markdown","source":"------------------------------------------------------------------------\n\n# Custom Model\n\n------------------------------------------------------------------------\n\n- The design of this custom model is illustrated in a draw.io diagram \n    - [Onedrive shared file of all-cnn-diagram.drawio diagram](https://onedrive.live.com/?authkey=%21AL6NGGK0%5FDdNURY&cid=10930FD9F7DD82DD&id=10930FD9F7DD82DD%21226797&parId=10930FD9F7DD82DD%21226791&o=OneUp) \n    - [link to draw.io of the model](https://app.diagrams.net/#W10930fd9f7dd82dd%2F10930FD9F7DD82DD!226797)","metadata":{}},{"cell_type":"markdown","source":"## References","metadata":{}},{"cell_type":"markdown","source":"### Links\n\n-   [10 CNN Architecture\n    Illustrations](https://towardsdatascience.com/illustrated-10-cnn-architectures-95d78ace614d#bca5)\n    -   [Visualizing pytorch\n        models](https://github.com/szagoruyko/pytorchviz)\n-   Main model building references\n    -   The [CT-3A github\n        repo](https://github.com/haydengunraj/COVIDNet-CT/search?q=model)\n        -   [tensorflow pretrained\n            models](https://github.com/haydengunraj/COVIDNet-CT/blob/master/docs/models.md)\n        -   How to [convert tensorflow checkpoints into pytorch\n            format](https://github.com/lernapparat/lernapparat/blob/master/style_gan/pytorch_style_gan.ipynb)\n            -   [pytorch\n                thread](https://discuss.pytorch.org/t/loading-tensorflow-checkpoints-with-pytorch/151750)\n        -   [pytorch\n            thread](https://discuss.pytorch.org/t/combining-trained-models-in-pytorch/28383/44)\n            about combining two existing models\n    -   [Pytorch resnext50\n        implementation](https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py#L792)\n    -   [pytorch beginner tutorial on building\n        model](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html)\n-   Other model building references\n    -   [Custom\n        Resnet](https://github.com/Arijit-datascience/pytorch_cifar10/blob/main/model/custom_resnet.py)\n    -   [Resnest convolution block\n        code](https://github.com/CVHuber/Convolution/blob/main/ResNeSt%20Block.py)\n    -   [A very clear implementation of InceptionV3](https://github.com/Moeo3/GoogLeNet-Inception-V3-pytorch/blob/master/googlenet_v3.py) that follows the naming of blocks in the diagram","metadata":{}},{"cell_type":"markdown","source":"## Components","metadata":{}},{"cell_type":"code","source":"# modified from https://github.com/Moeo3/GoogLeNet-Inception-V3-pytorch/blob/master/googlenet_v3.py#L46\nclass Conv2d_BN(Module):\n    def __init__(self, in_channels, out_channels, kernel, stride=1, padding=0, groups=1, acti=True):\n        super().__init__() # same as super(Conv2d_BN, self).__init__()\n        if acti:\n            self.conv2d_bn = Sequential(\n                Conv2d(in_channels, out_channels, kernel, stride, padding, groups=groups, bias=False),\n                BatchNorm2d(out_channels),\n                LeakyReLU(0.2, inplace=True)\n            )\n        else:\n            self.conv2d_bn = Sequential(\n                Conv2d(in_channels, out_channels, kernel, stride, padding, groups=groups, bias=False),\n                BatchNorm2d(out_channels)\n            )\n\n    def forward(self, x):\n        return self.conv2d_bn(x)\n\n    def out_channels(self):\n      return next(self.conv2d_bn.children()).out_channels\n\n\n# Taken from https://github.com/pytorch/vision/blob/main/torchvision/models/googlenet.py#L63\nclass StemBlock(Module):\n    def __init__(self, in_channels=3):\n        super().__init__()\n        # For simplicity Sequential module can be used here, explicitly name every layer for practise and readibility\n        self.conv1 = Conv2d_BN(in_channels, out_channels=64, kernel=7, stride=2, padding=3)\n        self.maxpool1 = MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n        self.conv2 = Conv2d_BN(in_channels=self.conv1.out_channels(), out_channels=80, kernel=1)\n        self.conv3 = Conv2d_BN(in_channels=self.conv2.out_channels(), out_channels=192, kernel=3, padding=1)\n        self.maxpool2 = MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n\n    def forward(self, x):\n        # N x 3 x 224 x 224\n        x = self.conv1(x)\n        # N x 64 x 112 x 112\n        x = self.maxpool1(x)\n        # N x 64 x 56 x 56\n        x = self.conv2(x)\n        # N x 80 x 56 x 56\n        x = self.conv3(x)\n        # N x 192 x 56 x 56\n        return self.maxpool2(x)\n        # N x 192 x 28 x 28\n\n    def out_channels(self):\n      # unable to access output size of MaxPool2d, use hard-coded formula instead\n      return math.floor(self.conv3.out_channels()/2)\n\n\n# https://stackoverflow.com/questions/4950155/objects-as-keys-in-python-dictionaries\nclass BlockType(Enum):\n    CONV = enum.auto()\n    IDENTITY = enum.auto()\n\n    def __eq__(self, other):\n        return self.name == other.name and self.value == other.value\n\n    def __hash__(self):\n        return hash(f\"{self.name}:{self.value}\")\n\n# Generalize ConvBlock and Identity block as ResidualBlock:\n# https://github.com/maciejbalawejder/Deep-Learning-Collection/blob/main/ConvNets/ResNeXt/resnext_pytorch.py\nclass ResidualBlock(Module):\n    def __init__(self, in_channels, out_channels, block_type: BlockType, stride, cardinatlity=32):\n        super().__init__()\n        assert out_channels % 32 == 0\n        self.C = cardinatlity\n        self.block_type = block_type\n        inner_channels = out_channels // 2\n        self.conv_tower = Sequential(\n            Conv2d_BN(in_channels, inner_channels, kernel=1),\n            Conv2d_BN(inner_channels, inner_channels, kernel=3, stride=stride, padding=1, groups=self.C),\n            Conv2d_BN(inner_channels, out_channels, kernel=1, acti=None)\n        )\n        if self.block_type is BlockType.CONV:\n            self.downsample = Conv2d_BN(in_channels, out_channels, kernel=1, stride=stride, acti=None)\n        self.relu = LeakyReLU(0.2, inplace=True)\n\n    def forward(self, x):\n        out = self.conv_tower(x)\n        if self.block_type is BlockType.CONV:\n            x = self.downsample(x)\n        out = self.relu(torch.add(out,x))\n        return out\n\n    def out_channels(self):\n      # unable to access output size of MaxPool2d, use hard-coded formula instead\n      gen = self.conv_tower.children()\n      last = next(gen)\n      for last in gen: pass\n      return last.out_channels()\n\n\n# taken from https://github.com/reppertj/earworm/blob/a2d8a70085748da5db378f7f5f68ad8c2926a274/modeling/music_metric_learning/modules/inception.py#L93\nclass ReductionBlock(Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        # previously mistakenly thought conv3_pooling_out is this layer out_channel, turn out that the out_channel is the total channels of the 3 layers\n        # assert (out_channels * 8 // 3) % 16 == 0\n        # conv5_out = out_channels * 2 // 3\n        # conv3_pooling_out = out_channels\n\n        assert out_channels % 16 == 0\n        conv5_out = out_channels // 4\n        conv3_pooling_out = conv5_out * 3 // 2\n        self.conv3 = Conv2d_BN(in_channels, conv3_pooling_out, kernel=3, stride=2)\n        self.conv5 = Sequential(\n            Conv2d_BN(in_channels       , conv5_out * 3 // 4, kernel=1),\n            Conv2d_BN(conv5_out * 3 // 4, conv5_out * 7 // 8, kernel=3, padding=1),\n            Conv2d_BN(conv5_out * 7 // 8, conv5_out         , kernel=3, stride=2),\n        )\n        self.pooling = Sequential(\n            MaxPool2d(3, stride=2),\n            Conv2d_BN(in_channels, conv3_pooling_out, kernel=1),\n        )\n\n    def forward(self, x):\n        return torch.cat((self.conv3(x), self.conv5(x), self.pooling(x)), dim=1)\n\n\nIN_CHAN=\"in_chan\"\nOUT_CHAN=\"out_chan\"\nclass CovidNetBlock(Module):\n    def __init__(self, residual_block_layout: dict, out_channels):\n        super().__init__()\n        chan_dict_list = [l for k, v in residual_block_layout.items() for l in v if isinstance(k, BlockType) and isinstance(v, list) and isinstance(l, dict)]\n\n        print(f\"Creating CovidNetBlock with layout length of {len(chan_dict_list)}\")\n        self.blocks = Sequential()\n        for k,v in residual_block_layout.items():\n            for chan_dict in v:\n                # print(f\"DEBUG_LOG - creating ResidualBlock with in_chan:{chan_dict[IN_CHAN]}; out_chan:{chan_dict[OUT_CHAN]}; block_type:{k}\")\n                self.blocks.append(ResidualBlock(chan_dict[IN_CHAN], chan_dict[OUT_CHAN], k, 1))\n        last_out_chan = chan_dict_list[-1][OUT_CHAN] # get last layers output channels count\n        self.blocks.append(ReductionBlock(last_out_chan, out_channels))\n\n    def forward(self, x):\n        return self.blocks(x)","metadata":{"execution":{"iopub.status.busy":"2023-02-18T02:53:00.216342Z","iopub.execute_input":"2023-02-18T02:53:00.216710Z","iopub.status.idle":"2023-02-18T02:53:00.253028Z","shell.execute_reply.started":"2023-02-18T02:53:00.216675Z","shell.execute_reply":"2023-02-18T02:53:00.251710Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Full Model","metadata":{}},{"cell_type":"code","source":"# https://onlinegdb.com/t9CIm197r\nclass CovidnetModel(Module):\n    def __init__(\n        self, \n        classes : int = 3,\n        ):\n        super().__init__()\n        \n        self.stem = StemBlock()\n\n        PRE_FC_OUT_CHAN = 192\n        residual_block_layout = {\n            BlockType.CONV:[\n                dict(in_chan=192, out_chan=256),\n                dict(in_chan=256, out_chan=512),\n                dict(in_chan=512, out_chan=1024),\n            ],\n            BlockType.IDENTITY:[dict(in_chan=1024, out_chan=1024)]\n        }\n        self.blocks = Sequential(\n            CovidNetBlock(residual_block_layout, 192),\n            CovidNetBlock(residual_block_layout, PRE_FC_OUT_CHAN)\n        )\n        \n        self.global_avg_pool = AdaptiveAvgPool2d((1,1))\n        self.fc = Linear(PRE_FC_OUT_CHAN, classes)\n\n    def forward(self, x):\n        # 3 x 224 x 224\n        x = self.stem(x)\n        # 192 x 28 x 28\n        x = self.blocks(x)\n        x = self.global_avg_pool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        return x","metadata":{"outputId":"631e7380-b393-4786-be6a-6166b9b785aa","execution":{"iopub.status.busy":"2023-02-18T02:53:00.254476Z","iopub.execute_input":"2023-02-18T02:53:00.255203Z","iopub.status.idle":"2023-02-18T02:53:00.266333Z","shell.execute_reply.started":"2023-02-18T02:53:00.255151Z","shell.execute_reply":"2023-02-18T02:53:00.264996Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"------------------------------------------------------------------------\n\n# Training & Validation\n\n------------------------------------------------------------------------","metadata":{}},{"cell_type":"markdown","source":"## Helper Functions","metadata":{}},{"cell_type":"code","source":"LOG_DIR = os.path.join(CURR_DIR, \"log\")\nRESULT_DIR = os.path.join(CURR_DIR, 'result')\ncurr_model = \"\"\n\ndef log_to_file(txt=None, print_to_console_only=False):\n  if txt is None:\n    txt = ''\n  txt += '\\n'\n  print(txt)\n  if print_to_console_only:\n    return\n  if not path.exists(LOG_DIR):\n    os.mkdir(LOG_DIR)\n  full_path = os.path.join(LOG_DIR, f'{curr_model}.txt')\n  with open(full_path, mode='a') as f:\n    f.write(txt)\n    \n# https://discuss.pytorch.org/t/clearing-the-gpu-is-a-headache/84762\n# Make sure to delete any references to tensor. Else this function will not have significant effect\ndef clean_vram():\n    gc.collect()\n    torch.cuda.empty_cache()\n\n# https://stackoverflow.com/questions/33162319/get-current-function-name-inside-that-function-using-python\ndef name_of_caller(frame=1):\n    \"\"\"\n    Return \"class.function_name\" of the caller or just \"function_name\".\n    \"\"\"\n    frame = sys._getframe(frame)\n    fn_name = frame.f_code.co_name\n    var_names = frame.f_code.co_varnames\n    if var_names:\n        if var_names[0] == \"self\":\n            self_obj = frame.f_locals.get(\"self\")\n            if self_obj is not None:\n                return f\"{type(self_obj).__name__}.{fn_name}\" \n        if var_names[0] == \"cls\":\n            cls_obj = frame.f_locals.get(\"cls\")\n            if cls_obj is not None:\n                return f\"{cls_obj.__name__}.{fn_name}\"\n    return fn_name","metadata":{"execution":{"iopub.status.busy":"2023-02-18T02:53:00.267872Z","iopub.execute_input":"2023-02-18T02:53:00.268573Z","iopub.status.idle":"2023-02-18T02:53:00.281329Z","shell.execute_reply.started":"2023-02-18T02:53:00.268529Z","shell.execute_reply":"2023-02-18T02:53:00.280174Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Define Functions to Initialize Deep Learning Models","metadata":{}},{"cell_type":"code","source":"model_constructors = {\n  models.alexnet.__name__: models.alexnet, \n  models.squeezenet1_1.__name__: models.squeezenet1_1,\n  models.resnet50.__name__: models.resnet50, \n  models.resnet101.__name__: models.resnet101,\n  models.resnet152.__name__: models.resnet152, \n  models.resnext101_32x8d.__name__: models.resnext101_32x8d, \n  models.densenet201.__name__: models.densenet201, \n  models.googlenet.__name__: models.googlenet, \n  models.vgg16.__name__: models.vgg16, \n  models.vgg19.__name__: models.vgg19, \n  models.inception_v3.__name__: models.inception_v3, \n  CovidnetModel.__name__: CovidnetModel,\n}\n\n# This is only available in pytorch v0.13\n# from torchvision.models import *\n# model_weights = {\n#   models.alexnet.__name__: models.AlexNet_Weights.DEFAULT,\n#   models.squeezenet1_1.__name__: SqueezeNet1_1_Weights.DEFAULT,\n#   models.resnet50.__name__: ResNet50_Weights.DEFAULT,\n#   models.resnet101.__name__: ResNet101_Weights.DEFAULT,\n#   models.resnet152.__name__: ResNet152_Weights.DEFAULT,\n#   models.resnext101_32x8d.__name__: ResNeXt101_32X8D_Weights.DEFAULT,\n#   models.densenet201.__name__: DenseNet201_Weights.DEFAULT,\n#   models.googlenet.__name__: GoogLeNet_Weights.DEFAULT,\n#   models.vgg16.__name__: VGG16_Weights.DEFAULT,\n#   models.vgg19.__name__: VGG19_Weights.DEFAULT,\n#   models.inception_v3.__name__: Inception_V3_Weights.DEFAULT,\n# }\n\n# Experiment around dropout & Learning Rate & different optimizer (Adam)\ndef init_model(name):\n  if not path.exists(RESULT_DIR):\n    os.mkdir(RESULT_DIR)\n\n  clean_vram()\n  seed_everything()\n  \n  # fine-tune pretrain models to our usecase\n  # https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html#initialize-and-reshape-the-networks\n  NUM_CLASSES = len(class_names)\n  DROPOUT = 0.5\n  if name == CovidnetModel.__name__:\n    model = model_constructors[name](NUM_CLASSES)\n  else:\n    model = model_constructors[name](True)\n    if name == models.alexnet.__name__ or name == models.vgg16.__name__ or name == models.vgg19.__name__:\n      num_ftrs = model.classifier[6].in_features\n      model.classifier[6] = Linear(num_ftrs, NUM_CLASSES)\n      # model.classifier[6] = Sequential(\n      #   Dropout(DROPOUT),\n      #   Linear(num_ftrs, NUM_CLASSES)\n      # )\n    elif name == models.densenet201.__name__:\n      num_ftrs = model.classifier.in_features\n      model.classifier = Linear(num_ftrs, NUM_CLASSES)\n      # model.classifier = Sequential(\n      #   Dropout(DROPOUT),\n      #   Linear(num_ftrs, NUM_CLASSES)\n      # )\n    elif name == models.squeezenet1_1.__name__:\n      model.classifier = Conv2d(512, NUM_CLASSES, kernel_size=(1,1), stride=(1,1))\n      # model.classifier = Sequential(\n      #   Dropout(DROPOUT),\n      #   Conv2d(512, NUM_CLASSES, kernel_size=(1,1), stride=(1,1))\n      # )\n      model.num_classes = NUM_CLASSES\n    elif name == models.inception_v3.__name__:\n      auxLogits_num_ftrs = model.AuxLogits.fc.in_features\n      model.AuxLogits.fc = Linear(auxLogits_num_ftrs, NUM_CLASSES)\n      # model.AuxLogits.fc = Sequential(\n      #   Dropout(DROPOUT),\n      #   Linear(auxLogits_num_ftrs, NUM_CLASSES)\n      # )\n      primary_num_ftrs = model.fc.in_features\n      model.fc = Linear(primary_num_ftrs, NUM_CLASSES)\n      # model.fc = Sequential(\n      #   Dropout(DROPOUT),\n      #   Linear(primary_num_ftrs, NUM_CLASSES)\n      # )\n    else:\n      # resnet, resnext & googlenet\n      num_ftrs = model.fc.in_features\n      model.fc= Linear(num_ftrs, NUM_CLASSES)\n      # model.fc = Sequential(\n      #   Dropout(DROPOUT),\n      #   Linear(num_ftrs, NUM_CLASSES)\n      # )\n\n  model = model.to(device)\n  criterion = CrossEntropyLoss()\n  optimizer= optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n  exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n  if is_gpu_avail():\n    # Use Automatic Mixed Precision as an attempt to solve CUDA out of memory and to speed things up\n    # https://pytorch.org/tutorials/recipes/recipes/amp_recipe.html#all-together-automatic-mixed-precision\n    scaler = torch.cuda.amp.GradScaler()\n  else:\n    raise RuntimeError('This code only support machine with GPU.')\n\n  # print('=====================================')\n  print(f'{name} is initialized')\n  # print('=====================================')\n  # print(model)\n  return model, criterion, optimizer, scaler\n\n# https://pytorch.org/tutorials/beginner/saving_loading_models.html\n# https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html\ndef save_model(perf_metrics, model, optimizer, scaler, history, model_path):\n  torch.save({\n    'perf_metrics': perf_metrics,\n    'model_state_dict': model.state_dict(),\n    'optimizer_state_dict': optimizer.state_dict(),\n    \"scaler_state_dict\": scaler.state_dict(),\n    'history': history,\n    }, model_path)\n\ndef load_model(model, optimizer, scaler, model_path):\n  if not os.path.exists(model_path):\n    log_to_file(f\">>> WARN: {name_of_caller()}() model path '{model_path}' don't exist!\")\n    return None, model, optimizer, scaler, None, None\n  checkpoint = torch.load(model_path)\n  perf_metrics = checkpoint['perf_metrics']\n  model.load_state_dict(checkpoint['model_state_dict'])\n  # model.load_state_dict(checkpoint['model_state_dict'], strict=False) # https://stackoverflow.com/questions/54058256/runtimeerror-errors-in-loading-state-dict-for-resnet\n  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n  scaler.load_state_dict(checkpoint['scaler_state_dict'])\n  history = checkpoint['history']\n  total_epoch = len(history) - 1\n  del checkpoint\n\n  return perf_metrics, model, optimizer, scaler, history, total_epoch","metadata":{"execution":{"iopub.status.busy":"2023-02-18T02:53:00.289339Z","iopub.execute_input":"2023-02-18T02:53:00.289589Z","iopub.status.idle":"2023-02-18T02:53:00.321083Z","shell.execute_reply.started":"2023-02-18T02:53:00.289566Z","shell.execute_reply":"2023-02-18T02:53:00.319965Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Define Function to Train Models","metadata":{}},{"cell_type":"code","source":"# training and validation loops\ndef train(model,\n    criterion,\n    optimizer,\n    scaler,\n    train_dataloader,\n    valid_dataloader,\n    model_path,\n    max_epochs_stop=10,\n    n_epochs=400,\n    min_epoch=300,\n    print_every=1):\n    \n    epochs_no_improve = 0\n    perf = {\n        'best_epoch': 0,\n        'valid_loss_min': np.Inf,\n        'valid_best_acc': 0,\n    }\n    total_epoch = 0\n\n    try:\n        if os.path.exists(model_path):\n            perf, model, optimizer, scaler, history, total_epoch = load_model(model, optimizer, scaler, model_path)\n            log_to_file(f'Model has been trained for: {total_epoch} epochs.')\n            log_to_file(f\"Best epoch: {perf['best_epoch']} with loss: {perf['valid_loss_min']:.4f} and acc: {100 * perf['valid_best_acc']:.2f}%\\n\")\n        else:\n            history = []\n            log_to_file(f'Starting Training from Scratch.\\n')\n    except:\n        history = []\n        log_to_file(f'exception: start from scratch.\\n')\n\n    overall_start = time.time()\n    if total_epoch >= n_epochs:\n        log_to_file(f'Model has been fully trained. n_epochs specified is: {n_epochs} epochs.')\n        history = pd.DataFrame(\n            history,\n            columns=['train_loss', 'valid_loss','train_acc', 'valid_acc'])\n        return model, history, perf\n\n    seed_everything()\n\n    # Main loop - continue training on where we left off if there's a saved model\n    for epoch in range(total_epoch, n_epochs):\n        # keep track of training and validation loss each epoch\n        train_loss = 0.0\n        valid_loss = 0.0\n\n        train_acc = 0\n        valid_acc = 0\n\n        # Set to training\n        model.train()\n        start = time.time()\n        for ii, (data, target) in enumerate (train_dataloader):\n            data, target = data.cuda(), target.cuda()\n            optimizer.zero_grad()\n\n            # only for inception_v3 - https://discuss.pytorch.org/t/why-auxiliary-logits-set-to-false-in-train-mode/40705/15\n            with torch.cuda.amp.autocast():\n              # output, aux_output = model(data)\n              # loss1 = criterion(output, target)\n              # loss2 = criterion(aux_output, target)\n              # loss = loss1 + 0.4*loss2\n              output = model(data)\n              loss = criterion(output, target)\n            # loss.backward()\n            # optimizer.step()\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n\n            train_loss += loss.item() * data.size(0)\n            _, pred = torch.max(output, dim=1)\n            correct_tensor = pred.eq(target.data.view_as(pred))\n            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n            train_acc += accuracy.item() * data.size(0)\n            print(\n                f'Epoch: {epoch}\\t{100 * (ii + 1) / len(train_dataloader):.2f}% complete. {time.time() - start:.2f} seconds elapsed in epoch.', end=\"\\r\")\n            \n            # cleanup to save VRAM\n            del data, target\n#             clean_vram()\n\n        # After training loops ends, start validation\n        else:\n            with torch.no_grad():\n                model.eval()\n                for data, target in valid_dataloader:\n                    if is_gpu_avail():\n                        data, target = data.cuda(), target.cuda()\n                    output = model(data)\n                    loss = criterion(output, target)\n                    valid_loss += loss.item() * data.size(0)\n                    _, pred = torch.max(output, dim=1)\n                    correct_tensor = pred.eq(target.data.view_as(pred))\n                    accuracy = torch.mean(\n                        correct_tensor.type(torch.FloatTensor))\n                    valid_acc += accuracy.item() * data.size(0)\n                    \n                    # cleanup to save VRAM\n                    del data, target\n#                     clean_vram()\n                train_loss = train_loss / train_data_size\n                valid_loss = valid_loss / valid_data_size\n                train_acc = train_acc / train_data_size\n                valid_acc = valid_acc / valid_data_size\n                history.append([train_loss, valid_loss,train_acc, valid_acc])\n                if (epoch + 1) % print_every == 0:\n                    log_to_file(f'Epoch: {epoch}', True)\n                    log_to_file(\n                        f'Training Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}',\n                        True\n                    )\n                    log_to_file(\n                        f'Training Accuracy: {100 * train_acc:.2f}%\\t Validation Accuracy: {100 * valid_acc:.2f}% \\n',\n                        True\n                    )\n          \n                if valid_loss < perf['valid_loss_min']:\n                    epochs_no_improve = 0\n                    perf['best_epoch'] = epoch\n                    perf['valid_loss_min'] = valid_loss\n                    perf['valid_best_acc'] = valid_acc\n                    save_model(perf, model, optimizer, scaler, history, model_path)\n                else:\n                    # disable early stopping and always save, remove this to reenable early stopping\n                    save_model(perf, model, optimizer, scaler, history, model_path)\n#                     epochs_no_improve += 1\n#                     # Trigger early stopping\n#                     if epoch > min_epoch and epochs_no_improve >= max_epochs_stop:\n#                         log_to_file(\n#                             f\"\\nEarly Stopping! Total epochs: {epoch}. Best epoch: {perf['best_epoch']} with loss: {perf['valid_loss_min']:.4f} and acc: {100 * perf['valid_best_acc']:.2f}%\"\n#                         )\n#                         total_time = time.time() - overall_start\n#                         log_to_file(\n#                             f'{total_time:.4f} total seconds elapsed. {total_time / (epoch+1):.4f} seconds per epoch.'\n#                         )\n#                         log_to_file()\n\n#                         # Load the best state from saved model\n#                         _, model, optimizer, scaler, _, _ = load_model(model, optimizer, scaler, model_path)\n#                         # save the full history\n#                         save_model(perf, model, optimizer, scaler, history, model_path)\n\n#                         # Format history\n#                         history = pd.DataFrame(\n#                             history,\n#                             columns=[\n#                                 'train_loss', 'valid_loss', 'train_acc',\n#                                 'valid_acc'\n#                             ])\n#                         return model, history, perf\n    \n    total_time = time.time() - overall_start\n    log_to_file(\n        f\"\\nBest epoch: {perf['best_epoch']} with loss: {perf['valid_loss_min']:.4f} and acc: {100 * perf['valid_best_acc']:.4f}%\"\n    )\n    log_to_file(\n        f\"{total_time:.4f} total seconds elapsed. {total_time / (perf['best_epoch']+1):.4f} seconds per epoch.\"\n    )\n    log_to_file()\n\n    # Load the best state from saved model\n    _, model, optimizer, scaler, _, _ = load_model(model, optimizer, scaler, model_path)\n    # save the full history\n    save_model(perf, model, optimizer, scaler, history, model_path)\n\n    # Format history\n    history = pd.DataFrame(\n        history,\n        columns=['train_loss', 'valid_loss','train_acc', 'valid_acc'])\n    \n    return model, history, perf\n\n\ndef save_train_val_loss_graph(history, perf):\n  plt.figure(figsize=(8, 6))\n  for c in ['train_loss', 'valid_loss']:\n      plt.plot(\n          history[c], label=c)\n\n  title = f'{curr_model} - Training and Validation Losses'\n  full_path = os.path.join(RESULT_DIR, f'{title}.png')\n  plt.xlabel('Epochs')\n  plt.ylabel('Average Losses')\n  plt.title(title)\n  plt.axvline(x=perf['best_epoch'], color='r', label='best_epoch')\n  plt.legend()\n  plt.savefig(full_path, bbox_inches='tight')\n\n\ndef save_train_val_acc_graph(history, perf):\n  plt.figure(figsize=(8, 6))\n  for c in ['train_acc', 'valid_acc']:\n      plt.plot(\n          100 * history[c], label=c)\n      \n  title = f'{curr_model} - Training and Validation Accuracy'\n  full_path = os.path.join(RESULT_DIR, f'{title}.png')\n  plt.xlabel('Epochs')\n  plt.ylabel('Average Accuracy')\n  plt.title(title)\n  plt.axvline(x=perf['best_epoch'], color='r', label='best_epoch')\n  plt.legend()\n  plt.savefig(full_path, bbox_inches='tight')","metadata":{"execution":{"iopub.status.busy":"2023-02-18T02:53:00.325910Z","iopub.execute_input":"2023-02-18T02:53:00.328416Z","iopub.status.idle":"2023-02-18T02:53:00.368151Z","shell.execute_reply.started":"2023-02-18T02:53:00.328380Z","shell.execute_reply":"2023-02-18T02:53:00.367038Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Define Functions to Visualize Prediction","metadata":{}},{"cell_type":"code","source":"def imshow(inp, title=None):\n    inp = inp.numpy().transpose((1, 2, 0))\n    # mean = np.array([0.485, 0.456, 0.406])\n    # std = np.array([0.229, 0.224, 0.225])\n    # inp = std * inp + mean\n    # inp = np.clip(inp, 0, 1)\n    plt.figure(figsize=[15, 15])\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n\n# confusion matrix \ndef getConfusionMatrix(model, dataloader, is_test=False, show_image=False, print_to_console_only=False):\n    model.eval()\n    confusion_matrix=np.zeros((2,2),dtype=int)\n    num_images=test_data_size\n    \n    with torch.no_grad():\n        for i, (data,target) in enumerate(dataloader):\n            data = data.to(device)\n            target = target.to(device)\n            \n            output = model(data) \n            _, pred = torch.max(output, 1)\n            \n            for j in range(data.size()[0]): \n                if pred[j]==1 and target[j]==1:\n                    term='TP'\n                    confusion_matrix[0][0]+=1\n                elif pred[j]==1 and target[j]==0:\n                    term='FP'\n                    confusion_matrix[1][0]+=1\n                elif pred[j]==0 and target[j]==1:\n                    term='FN'\n                    confusion_matrix[0][1]+=1\n                elif pred[j]==0 and target[j]==0:\n                    term='TN'\n                    confusion_matrix[1][1]+=1\n            \n                if show_image:\n                    log_to_file(f'predicted: {class_names[pred[j]]}', print_to_console_only)\n                    log_to_file(term, print_to_console_only)\n                    imshow(data.cpu().data[j])\n        \n        log_to_file(None, print_to_console_only)\n        category = 'Test' if is_test else 'Validation'\n        log_to_file('=====================', print_to_console_only)\n        log_to_file(f'{category} Results ', print_to_console_only)\n        log_to_file('=====================', print_to_console_only)\n        log_to_file('Confusion Matrix: ', print_to_console_only)\n        log_to_file(np.array2string(confusion_matrix), print_to_console_only)\n        log_to_file(None, print_to_console_only)\n\n        log_to_file(f'Sensitivity: {100*confusion_matrix[0][0]/(confusion_matrix[0][0]+confusion_matrix[0][1])}', print_to_console_only)\n        log_to_file(f'Specificity: {100*confusion_matrix[1][1]/(confusion_matrix[1][1]+confusion_matrix[1][0])}', print_to_console_only)\n        log_to_file(f'PPV: {100*confusion_matrix[0][0]/(confusion_matrix[0][0]+confusion_matrix[1][0])}', print_to_console_only)\n        log_to_file(f'NPV: {100*confusion_matrix[1][1]/(confusion_matrix[1][1]+confusion_matrix[0][1])}', print_to_console_only)\n        log_to_file(f'Accuracy: {100*(confusion_matrix[0][0]+confusion_matrix[1][1])/(confusion_matrix[0][0]+confusion_matrix[0][1]+confusion_matrix[1][1]+confusion_matrix[1][0])}', print_to_console_only)\n        log_to_file(f'F1-Score: {(2*confusion_matrix[0][0])/(2*confusion_matrix[0][0]+confusion_matrix[1][0]+confusion_matrix[0][1])}', print_to_console_only)\n        log_to_file(None, print_to_console_only)\n    return confusion_matrix\n\n\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-18T02:53:00.372991Z","iopub.execute_input":"2023-02-18T02:53:00.373372Z","iopub.status.idle":"2023-02-18T02:53:00.393740Z","shell.execute_reply.started":"2023-02-18T02:53:00.373335Z","shell.execute_reply":"2023-02-18T02:53:00.392528Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Run all models - Init Models + Training","metadata":{}},{"cell_type":"code","source":"model_list = [\n    models.alexnet.__name__, # 0\n    models.squeezenet1_1.__name__, #1\n    models.resnet50.__name__, # 2\n    models.resnet101.__name__, # 3\n    models.resnet152.__name__, # 4\n    models.resnext101_32x8d.__name__, # 5\n    models.densenet201.__name__, # 6\n    models.googlenet.__name__, # 7\n    models.vgg16.__name__, # 8\n    models.vgg19.__name__, #9\n    models.inception_v3.__name__, #10\n    CovidnetModel.__name__, #11\n]\n\nfor i in range(0, len(model_list)):\n  # https://github.com/pytorch/pytorch/issues/50198\n  # skipped these because cannot use deterministic algorithm\n#   skip_model = [0, 1, 5, 8, 9, 10]\n#   skip_model = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n#   if i in skip_model:\n#     continue\n  if model_list[i] is not models.resnet50.__name__:\n    continue\n  curr_model = model_list[i]\n\n  # Initialize model, criterion and optimizer\n  model, criterion, optimizer, scaler = init_model(curr_model)\n\n#   Training & Validation\n  model, history, perf = train(\n      model,\n      criterion,\n      optimizer,\n      scaler,\n      train_loader,\n      val_loader,\n      model_path=f'{path.join(RESULT_DIR, curr_model)}.pt',\n      max_epochs_stop=5,  # Early stopping intialization\n      n_epochs=100,\n      min_epoch=100,\n      print_every=10)\n\n  history\n  save_train_val_loss_graph(history, perf)\n  save_train_val_acc_graph(history, perf)\n  getConfusionMatrix(model, val_loader)","metadata":{"execution":{"iopub.status.busy":"2023-02-13T05:54:52.704552Z","iopub.execute_input":"2023-02-13T05:54:52.704834Z","iopub.status.idle":"2023-02-13T09:07:54.529640Z","shell.execute_reply.started":"2023-02-13T05:54:52.704810Z","shell.execute_reply":"2023-02-13T09:07:54.528615Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"env: PYTHONHASHSEED=18\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth\" to /root/.cache/torch/hub/checkpoints/resnext101_32x8d-8ba56ff5.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/340M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee8462b63d1c44089bcb2c2c9f52d55f"}},"metadata":{}},{"name":"stdout","text":"resnext101_32x8d is initialized\nModel has been trained for: 93 epochs.\n\nBest epoch: 63 with loss: 0.0082 and acc: 99.80%\n\n\nenv: PYTHONHASHSEED=18\nEpoch: 99\t100.00% complete. 1567.08 seconds elapsed in epoch.\n\nTraining Loss: 0.0163 \tValidation Loss: 0.0373\n\nTraining Accuracy: 99.49%\t Validation Accuracy: 99.30% \n\n\n\nBest epoch: 63 with loss: 0.0082 and acc: 99.8002%\n\n11512.6252 total seconds elapsed. 179.8848 seconds per epoch.\n\n\n\n\n\n=====================\n\nValidation Results \n\n=====================\n\nConfusion Matrix: \n\n[[ 98   2]\n [  0 168]]\n\n\n\nSensitivity: 98.0\n\nSpecificity: 100.0\n\nPPV: 100.0\n\nNPV: 98.82352941176471\n\nAccuracy: 99.25373134328358\n\nF1-Score: 0.98989898989899\n\n\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 576x432 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 576x432 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"## Download Results\n<a href=\"/kaggle/working/result/CovidnetModel - Training and Validation Accuracy.png\"> CovidnetModel - Training and Validation Accuracy.png </a> </br>\n<a href=\"/kaggle/working/result/CovidnetModel - Training and Validation Losses.png\"> CovidnetModel - Training and Validation Losses.png </a> </br>\n<a href=\"/kaggle/working/result/CovidnetModel.pt\"> CovidnetModel.pt </a> </br>","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/result\nfrom IPython.display import FileLink\n# FileLink(r'CovidnetModel - Training and Validation Accuracy.png')\n# FileLink(r'CovidnetModel - Training and Validation Losses.png')\nFileLink(r'CovidnetModel.pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"------------------------------------------------------------------------\n\n# Final Evaluation\n\n------------------------------------------------------------------------\n- After selecting the best hyperparameters and models, use the model to predict the result on the test images\n    - Get the confusion matrix and prediction similar to what we did for validation images\n- Run GradCam to visualize which regions in the image the model are activated","metadata":{}},{"cell_type":"markdown","source":"## Run Test","metadata":{}},{"cell_type":"code","source":"def reloadModel():\n  saved_model_path = f'{path.join(RESULT_DIR, curr_model)}.pt'\n  if os.path.exists(saved_model_path):\n    model, criterion, optimizer, scaler = init_model(curr_model)\n    return load_model(model, optimizer, scaler, saved_model_path)\n  else:\n    return None, None, None, None, None, None\n\nmodel_list = [\n    models.alexnet.__name__, # 0\n    models.squeezenet1_1.__name__, #1\n    models.resnet50.__name__, # 2\n    models.resnet101.__name__, # 3\n    models.resnet152.__name__, # 4\n    models.resnext101_32x8d.__name__, # 5\n    models.densenet201.__name__, # 6\n    models.googlenet.__name__, # 7\n    models.vgg16.__name__, # 8\n    models.vgg19.__name__, #9\n    models.inception_v3.__name__, #10\n    CovidnetModel.__name__, #11\n]\n\nfor i in range(0, len(model_list)):\n  skip_model = [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n  if i in skip_model:\n    continue\n  curr_model = model_list[i]\n  _, model, _, _, _, _ = reloadModel()\n  seed_everything()\n  if model:\n    trainable_parameters = count_parameters(model)\n    print(f'model: {curr_model}, number of trainable parameters: {trainable_parameters}')\n\ngetConfusionMatrix(model, test_loader, True)\n# visualize_test_prediction(model)","metadata":{"execution":{"iopub.status.busy":"2023-02-18T02:54:54.540714Z","iopub.execute_input":"2023-02-18T02:54:54.541087Z","iopub.status.idle":"2023-02-18T02:56:38.556634Z","shell.execute_reply.started":"2023-02-18T02:54:54.541057Z","shell.execute_reply":"2023-02-18T02:56:38.555613Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"env: PYTHONHASHSEED=18\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth\" to /root/.cache/torch/hub/checkpoints/resnext101_32x8d-8ba56ff5.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/340M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45981986472f41389b16ed4960e2e2cf"}},"metadata":{}},{"name":"stdout","text":"resnext101_32x8d is initialized\nenv: PYTHONHASHSEED=18\nmodel: resnext101_32x8d, number of trainable parameters: 86748483\n\n\n=====================\n\nTest Results \n\n=====================\n\nConfusion Matrix: \n\n[[ 99   2]\n [  0 168]]\n\n\n\nSensitivity: 98.01980198019803\n\nSpecificity: 100.0\n\nPPV: 100.0\n\nNPV: 98.82352941176471\n\nAccuracy: 99.25650557620818\n\nF1-Score: 0.99\n\n\n\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"array([[ 99,   2],\n       [  0, 168]])"},"metadata":{}}]},{"cell_type":"markdown","source":"## Run GradCam\n- This repo is used instead due to much better support with pytorch - https://github.com/frgfm/torch-cam\n- [This reference](https://github.com/jacobgil/pytorch-grad-cam) is obselete as need to find the layer manually, and facing `IndexError: index 2 is out of bounds for dimension 1 with size 2`","metadata":{}},{"cell_type":"code","source":"!pip install git+https://github.com/frgfm/torch-cam.git#egg=torchcam\nfrom torchvision.io.image import read_image\nfrom torchvision.transforms.functional import normalize, resize, to_tensor, to_pil_image\nfrom torchcam.cams import SmoothGradCAMpp\nfrom torchcam.utils import overlay_mask\nfrom PIL import ImageOps\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nimport math\n\n\"\"\" \nClass activation explorer using TorchCAM.\nIterate through validation database and overlay images with class activation \nheatmap.\n\nReference: https://github.com/frgfm/torch-cam \n\"\"\"\ndef runGradCam():\n  _, model, _, _, _, _ = reloadModel()\n  if model:\n    model.eval()\n    cam_extractor = SmoothGradCAMpp(model)\n\n    DATASET_TYPE = 'cam'\n    num_iter = 2\n    pred_probs = getPredProbs(model, DATASET_TYPE, num_iter)\n\n    seed_everything()\n    # NOTE: file path is only valid if dataset type is cam\n    for i, (img, cls, ori_path) in enumerate(data[DATASET_TYPE]):\n      if i >= num_iter:\n        break\n      \n      img = img.to(device)\n      # Preprocess your data and feed it to the model\n      out = model(img.unsqueeze(0))\n      # Retrieve the CAM by passing the class index and the model output\n      activation_map = cam_extractor(cls, out)\n\n      # Resize the CAM and overlay it\n      # https://matplotlib.org/stable/tutorials/colors/colormaps.html#miscellaneous\n      ori_img = to_pil_image(img)\n      result = overlay_mask(ori_img, to_pil_image(activation_map, mode='F'), colormap='jet', alpha=0.5)\n\n      # Display it\n      # https://matplotlib.org/stable/gallery/axes_grid1/simple_axesgrid.html\n      fig = plt.figure(figsize=(20., 20.))\n      grid = ImageGrid(fig, 111,  # similar to subplot(111)\n                      nrows_ncols=(1, 2),  # creates 1x2 grid of axes\n                      axes_pad=0.1,  # pad between axes in inch.\n                      )\n      for ax, im in zip(grid, [ori_img, result]):\n        # Iterating over the grid returns the Axes.\n        classStr = data[DATASET_TYPE].classes[cls]\n        ax.set_title(\"{:.4f}% Covid, \\n{:.4f}% NonCovid, Actual:{}, ImagePath:{}\".format(100*pred_probs[i,0],\n                                                                      100*pred_probs[i,1],\n                                                                      classStr, ori_path), fontsize=10)\n        ax.imshow(im)\n      title = f'{curr_model} - GradCam++ Visualization'\n      full_path = os.path.join(result_dir, f'{title}.png')\n      plt.savefig(full_path)\n      plt.show()\n\ncurr_model = models.resnext101_32x8d.__name__\nrunGradCam()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"------------------------------------------------------------------------\n\n# Playground\n\n------------------------------------------------------------------------\n\n> Testbed that is not compulsary for any part of this notebook","metadata":{}},{"cell_type":"markdown","source":"## Visualizing Models using PytorchViz\n\n-   https://pytorch.org/docs/stable/nn.html\n-   https://discuss.pytorch.org/t/combining-multiple-models-and-datasets/82623\n-   [Mandrin explanation of pytorch resnet\n    code](https://www.jianshu.com/p/90d61f53d15d)","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\n%pip install -U git+https://github.com/szagoruyko/pytorchviz.git@master\nfrom torchviz import make_dot, make_dot_from_trace","metadata":{"outputId":"9d20f8af-0489-4225-cdd1-4f8747a7c053"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from torchinfo import summary\n%pip install -U torchsummary\nfrom torchsummary import summary\n\nif is_gpu_avail():\n    device = torch.device('cuda')\n    torch.set_default_tensor_type('torch.cuda.FloatTensor')\nelse:\n    device = torch.device('cpu')\n\n\n# model = models.googlenet()\n# summary(model, (3, 299, 299))\n\n# model = ResidualBlock(192, 192, BlockType.IDENTITY, 1)\n# summary(model, (192, 28, 28))\n\n# model = ResidualBlock(192, 256, BlockType.CONV, 1) # also works if 192,192\n# summary(model, (192, 28, 28))\n\n# model = ResidualBlock(256, 320, BlockType.CONV, 1) # also works if 192,192\n# summary(model, (256, 28, 28))\n\n# model = ReductionBlock(1024, 192)\n# summary(model, (1024, 28, 28))\n\n# residual_block_layout = {\n#     BlockType.CONV:[\n#         dict(in_chan=192, out_chan=256),\n#         dict(in_chan=256, out_chan=512),\n#         dict(in_chan=512, out_chan=1024),\n#     ],\n#     BlockType.IDENTITY:[dict(in_chan=1024, out_chan=1024)]\n# }\n# model = CovidNetBlock(residual_block_layout, 192) \n# summary(model, (192, 28, 28))\n\nmodel = CovidnetModel()\nsummary(model, (3, 224, 224))\n\n# model = models.resnext50_32x4d()\n# summary(model, (3, 224, 224))\n\n# x = torch.randn(1, 3, 224, 224).requires_grad_(True)\n# y = model(x)\n# dot = make_dot(y, params=dict(model.named_parameters()))\n\n# dot.format = \"png\"\n# dot.render(render_model_pic_file)\n# files.download(f\"{render_model_pic_file}.{dot.format}\")","metadata":{"outputId":"374f5af4-8588-4f75-cf55-3c659c652ca1","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Investigate Image in Dataset","metadata":{}},{"cell_type":"code","source":"import subprocess\n\n# Specify all the filepath of the dataset\nDATA_DIR = \"/kaggle/input/covidxct\"\nDATASET_DIR = path.join(DATA_DIR, \"3A_images/\")\nDATASET_NAME = \"COVIDx_CT-3A\"\nTEST_SPLIT_FILE = path.join(DATA_DIR, f\"test_{DATASET_NAME}.txt\")\n\n# count number of images\n# !ls -Uba1 /content/data/3A_images | grep -c png\nls = subprocess.Popen((\"ls\", \"-Uba1\", DATASET_DIR), stdout=subprocess.PIPE)\noutput = subprocess.check_output((\"grep\", \"-c\", \"png\"), stdin=ls.stdout)\nprint(f\"number of images: {output.decode()}\")\n\n# list first 10 images\nls = subprocess.Popen((\"ls\", \"-Uba1\", DATASET_DIR), stdout=subprocess.PIPE)\noutput = subprocess.check_output((\"head\", \"-10\"), stdin=ls.stdout)\nfirst_10_lines = output.decode()\n# print(f\"first 10 images in {DATASET_DIR}:\\n{first_10_lines}\")\nimg_list = first_10_lines.split('\\n')\nfirst_png = next(filter(lambda img: \"png\" in img, img_list), None)\nprint(f\"first_png: {first_png}\\n\")","metadata":{"outputId":"dee59970-4dda-4616-d934-7638ab68dc23"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show the first test image, unbounded followed by bounded\nimport torch\nimport matplotlib.pyplot as plt\nimport torchvision.transforms.functional as torch_func_trans\nfrom PIL import Image\n\n# from https://github.com/haydengunraj/COVIDNet-CT/blob/d1c6be5202a78d5f8802e40ff6b5b9d57189c797/dataset.py#L108\ndef get_data_from_split_file(split_file):\n    \"\"\"Gets image filenames, classes and bboxes\"\"\"\n    files, classes, bboxes = [], [], []\n    with open(split_file, 'r') as f:\n        for line in f.readlines():\n            fname, cls, xmin, ymin, xmax, ymax = line.strip('\\n').split()\n            files.append(path.join(DATASET_DIR, fname))\n            classes.append(int(cls))\n            bboxes.append([int(xmin), int(ymin), int(xmax), int(ymax)])\n    return files, classes, bboxes\n\ndef bbox_to_topLeftOrigin_size(xmin, ymin, xmax, ymax):\n    top = ymax\n    left = xmin\n    height = ymax - ymin\n    width = xmax - xmin\n    return top, left, height, width\n\nfiles, classes, bbox = get_data_from_split_file(TEST_SPLIT_FILE)\nfirst_file_tuple = (files[0], classes[0], bbox[0])\n\nprint(f\"first image: {first_file_tuple[0]}\")\nif 0:\n    # this way of reading image is deprecated\n    img = plt.imread(first_file_tuple[0])\n\n    fig = plt.figure(figsize=(15,15))\n    plt.title(\"unbounded\")\n    _ = plt.imshow(img)\n    _ = plt.axis('off')\n\n    torch_img = torch.from_numpy(img)\n    print(f\"torch_img size: {torch_img.size()}\")\n    pytorch_size = bbox_to_topLeftOrigin_size(*first_file_tuple[2])\n    print(f\"pytorch_size: {pytorch_size}\")\n\n    cropped_img = torch_func_trans.crop(torch_img, *pytorch_size)\n    fig = plt.figure(figsize=(15,15))\n    plt.title(\"bounded\")\n    _ = plt.imshow(cropped_img)\n    _ = plt.axis('off')\n\n# This is the recommended method for opening image\n# https://pillow.readthedocs.io/en/stable/reference/Image.html#examples\nwith Image.open(first_file_tuple[0]) as im:\n    print(\"\\n\")\n    print(\"Unbounded image\")\n    IMG = im\n    display(im)\n\n    print(\"\\n\")\n    print(\"Bounded image\")\n    display(im.crop(first_file_tuple[2]))\n\n    # https://pillow.readthedocs.io/en/latest/reference/open_files.html#file-handling\n    print(\"\\n\")\n    print(\"Out of Scope Unbounded image\")\n    display(IMG)\n    ","metadata":{"outputId":"d0ccff4a-152e-48aa-8b8f-dadafcc7b42b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Investigate metadata.csv","metadata":{}},{"cell_type":"code","source":"import pandas as pd\npd.set_option('display.expand_frame_repr', False)\n\n# Specify all the filepath of the dataset\nDATA_DIR = \"/kaggle/input/covidxct\"\ndirs = [entry.name for entry in os.scandir(DATA_DIR) if entry.is_dir()]\nassert len(dirs) == 1 # expects to only have 1 folder that contains all the images\n\nDATASET_DIR = path.join(DATA_DIR, dirs[0])\nMETADATA_CSV = path.join(DATA_DIR, \"metadata.csv\")\n\nmeta_df = pd.read_csv(METADATA_CSV)\nprint(\"First 5 rows in metadata.csv0\")\nprint(meta_df.head(5))\nprint(f\"classes: {sorted(meta_df['finding'].unique())}\")\n\nunverified = meta_df['verified finding'].eq('No').sum()\nverified = meta_df['verified finding'].eq('Yes').sum()\nprint(f\"Not verified: {unverified}\")\nprint(f\"Verified: {verified}\")\n\nunverified_patient_ids = meta_df.loc[meta_df['verified finding'] == 'No', 'patient id'].unique()\nassert len(unverified_patient_ids) == unverified # patient id is expected to be unique in metadata.csv\nprint(f\"first unverified ID: {unverified_patient_ids[0]}\")\n\nverified_patient_ids = meta_df.loc[meta_df['verified finding'] == 'Yes', 'patient id'].unique()\nassert len(verified_patient_ids) == verified # patient id is expected to be unique in metadata.csv\nprint(f\"first verified ID: {verified_patient_ids[0]}\")\n\nimgs = [entry.name for entry in os.scandir(DATASET_DIR) if entry.is_file()]\nprint(f\"total images: {len(imgs)}\")\nprint(f\"first 10 images: {imgs[:10]}\")\nimgs_of_1_patient = [img for img in imgs if verified_patient_ids[0] in img]\nprint(f\"Images of patient ID {verified_patient_ids[0]}: {imgs_of_1_patient}\")","metadata":{"outputId":"f442a9a0-5034-4330-c596-c460d7f389a9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Investigating split dataset","metadata":{}},{"cell_type":"code","source":"# Specify all the filepath of the dataset\nDATA_DIR = \"/kaggle/input/covidxct\"\ndirs = [entry.name for entry in os.scandir(DATA_DIR) if entry.is_dir()]\nassert len(dirs) == 1 # expects to only have 1 folder that contains all the images\n\nDATASET_DIR = path.join(DATA_DIR, dirs[0])\nMETADATA_CSV = path.join(DATA_DIR, \"metadata.csv\")\n\nDATASET_NAME = \"COVIDx_CT-3A\"\nTRAIN_SPLIT_FILE = path.join(DATA_DIR, f\"train_{DATASET_NAME}.txt\")\nVAL_SPLIT_FILE = path.join(DATA_DIR, f\"val_{DATASET_NAME}.txt\")\nTEST_SPLIT_FILE = path.join(DATA_DIR, f\"test_{DATASET_NAME}.txt\")\nSPLIT_FILES = [TRAIN_SPLIT_FILE, VAL_SPLIT_FILE, TEST_SPLIT_FILE]\n\nfull_dataset = CovidNetDataset(DATASET_DIR, SPLIT_FILES)\nfull_data_len = len(full_dataset)\nprint(f\"Length of full dataset: {full_data_len}\")\n\nSEED = 18\nseed_everything(SEED)\nBATCH_SIZE = 64\n\n# # Defines ratios, w.r.t. whole dataset.\nratio_train = 0.8\nratio_val = 0.1\nratio_test = 0.1\ndummy_X = np.zeros(full_data_len)\nindexes = np.arange(full_data_len)\n\n# Produces test split. Uses train_test_split instead of StratifiedShuffleSplit to get x_remaining & y_remaining\n# to be used in the next step. \n# Note that an additional indexes array is provided\nx_remaining, X_test, y_remaining, Y_test, temp_train_index, test_index = train_test_split(\n    dummy_X, full_dataset.targets, indexes, test_size=ratio_test, stratify=full_dataset.targets, random_state=SEED)\n# train_index, test_index = next(\n#     StratifiedShuffleSplit(n_splits=1, test_size=ratio_test, random_state=SEED).split(\n#         dummy_X, full_dataset.targets\n#     )\n# )\n\nprint('*'*50)\nprint(\"temp_train\")\nprint('*'*50)\nprint(f\"First 10 index: {temp_train_index[:10]}\")\nprint(f\"First 10 label: {y_remaining[:10]}\")\nprint(f\"length of index: {len(temp_train_index)}\")\nprint(\">>>Distribution of labels:\")\nprint(f\"Normal: {y_remaining.count(0)}\")\nprint(f\"Pneunomia: {y_remaining.count(1)}\")\nprint(f\"Covid-19: {y_remaining.count(2)}\")\n\nprint()\nprint('*'*50)\nprint(\"test\")\nprint('*'*50)\nprint(f\"First 10 index: {test_index[:10]}\")\nprint(f\"First 10 label: {Y_test[:10]}\")\nprint(f\"length of index: {len(test_index)}\\n\")\nprint(\">>>Distribution of labels:\")\nprint(f\"Normal: {Y_test.count(0)}\")\nprint(f\"Pneunomia: {Y_test.count(1)}\")\nprint(f\"Covid-19: {Y_test.count(2)}\")\n\n# Adjusts val ratio, w.r.t. remaining dataset.\nratio_remaining = 1 - ratio_test\nratio_val_adjusted = ratio_val / ratio_remaining\n\n# Produces train and val splits.\nX_train, X_val, Y_train, Y_val, train_index, val_index = train_test_split(\n    x_remaining, y_remaining, temp_train_index, test_size=ratio_val_adjusted, stratify=y_remaining, random_state=SEED)\n\nprint()\nprint('*'*50)\nprint(\"train\")\nprint('*'*50)\nprint(f\"First 10 index: {train_index[:10]}\")\nprint(f\"First 10 label: {Y_train[:10]}\")\nprint(f\"length of index: {len(train_index)}\\n\")\nprint(\">>>Distribution of labels:\")\nprint(f\"Normal: {Y_train.count(0)}\")\nprint(f\"Pneunomia: {Y_train.count(1)}\")\nprint(f\"Covid-19: {Y_train.count(2)}\")\n\nprint()\nprint('*'*50)\nprint(\"val\")\nprint('*'*50)\nprint(f\"First 10 index: {val_index[:10]}\")\nprint(f\"First 10 label: {Y_val[:10]}\")\nprint(f\"length of index: {len(val_index)}\\n\")\nprint(\">>>Distribution of labels:\")\nprint(f\"Normal: {Y_val.count(0)}\")\nprint(f\"Pneunomia: {Y_val.count(1)}\")\nprint(f\"Covid-19: {Y_val.count(2)}\")","metadata":{"outputId":"6b8fad54-930b-4452-a1a6-aff1ba381edf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing Dataloader","metadata":{}},{"cell_type":"code","source":"import pprint\ndef imshow(inp, title=None):\n    inp = inp.numpy().transpose((1, 2, 0))\n    # mean = np.array([0.485, 0.456, 0.406])\n    # std = np.array([0.229, 0.224, 0.225])\n    # inp = std * inp + mean\n    # inp = np.clip(inp, 0, 1)\n    plt.figure(figsize=[15, 15])\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n\nseed_everything(19)\nclass_names, _ = full_dataset.find_classes()\ndata, classes = next(iter(train_loader)) # note that it is normal for warning about clipping here if the image has been normalized\n# out = torchvision.utils.make_grid(data)\n# imshow(out)\n# pp = pprint.PrettyPrinter(compact=True)\n# pp.pprint([class_names[x] for x in classes])\n\nprint(f\"Class: {classes[0]}\")\nout = data[0]\nimshow(out)","metadata":{"outputId":"151b91d7-9c07-41f3-ff2f-ac0139aaca5f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Trying Avalance","metadata":{}},{"cell_type":"code","source":"# https://changhsinlee.com/colab-import-python/\n!pip install requests\n!pip install avalanche-lib","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import requests\n\n# Save datagenerators as file to colab working directory\n# If you are using GitHub, make sure you get the \"Raw\" version of the code\nurl = 'https://raw.githubusercontent.com/ContinualAI/avalanche/master/examples/pytorchcv_models.py'\nr = requests.get(url)\n\n# make sure your filename is the same as how you want to import \nwith open('pytorchcv_models.py', 'w') as f:\n    f.write(r.text)\n\n# now we can import\nimport pytorchcv_models as pycv\nfrom types import SimpleNamespace\n\nargs = SimpleNamespace()\nargs.cuda = 0\npycv.main(args)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pretrained Model","metadata":{}},{"cell_type":"markdown","source":"### Helper Functions","metadata":{}},{"cell_type":"code","source":"LOG_DIR = os.path.join(CURR_DIR, \"log\")\nRESULT_DIR = os.path.join(CURR_DIR, 'result')\ncurr_model = \"\"\n\ndef log_to_file(txt=None, print_to_console_only=False):\n  if txt is None:\n    txt = ''\n  txt += '\\n'\n  print(txt)\n  if print_to_console_only:\n    return\n  if not path.exists(LOG_DIR):\n    os.mkdir(LOG_DIR)\n  full_path = os.path.join(LOG_DIR, f'{curr_model}.txt')\n  with open(full_path, mode='a') as f:\n    f.write(txt)\n    \n# https://discuss.pytorch.org/t/clearing-the-gpu-is-a-headache/84762\n# Make sure to delete any references to tensor. Else this function will not have significant effect\ndef clean_vram():\n    gc.collect()\n    torch.cuda.empty_cache()\n    \n# https://stackoverflow.com/questions/33162319/get-current-function-name-inside-that-function-using-python\ndef name_of_caller(frame=1):\n    \"\"\"\n    Return \"class.function_name\" of the caller or just \"function_name\".\n    \"\"\"\n    frame = sys._getframe(frame)\n    fn_name = frame.f_code.co_name\n    var_names = frame.f_code.co_varnames\n    if var_names:\n        if var_names[0] == \"self\":\n            self_obj = frame.f_locals.get(\"self\")\n            if self_obj is not None:\n                return f\"{type(self_obj).__name__}.{fn_name}\" \n        if var_names[0] == \"cls\":\n            cls_obj = frame.f_locals.get(\"cls\")\n            if cls_obj is not None:\n                return f\"{cls_obj.__name__}.{fn_name}\"\n    return fn_name","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define Function to Initialize Deep Learning Models","metadata":{}},{"cell_type":"code","source":"model_constructors = {\n  models.alexnet.__name__: models.alexnet, \n  models.squeezenet1_1.__name__: models.squeezenet1_1,\n  models.resnet50.__name__: models.resnet50, \n  models.resnet101.__name__: models.resnet101,\n  models.resnet152.__name__: models.resnet152, \n  models.resnext101_32x8d.__name__: models.resnext101_32x8d, \n  models.densenet201.__name__: models.densenet201, \n  models.googlenet.__name__: models.googlenet, \n  models.vgg16.__name__: models.vgg16, \n  models.vgg19.__name__: models.vgg19, \n  models.inception_v3.__name__: models.inception_v3, \n}\n\nfrom torchvision.models import *\nmodel_weights = {\n  models.alexnet.__name__: AlexNet_Weights.DEFAULT,\n  models.squeezenet1_1.__name__: SqueezeNet1_1_Weights.DEFAULT,\n  models.resnet50.__name__: ResNet50_Weights.DEFAULT,\n  models.resnet101.__name__: ResNet101_Weights.DEFAULT,\n  models.resnet152.__name__: ResNet152_Weights.DEFAULT,\n  models.resnext101_32x8d.__name__: ResNeXt101_32X8D_Weights.DEFAULT,\n  models.densenet201.__name__: DenseNet201_Weights.DEFAULT,\n  models.googlenet.__name__: GoogLeNet_Weights.DEFAULT,\n  models.vgg16.__name__: VGG16_Weights.DEFAULT,\n  models.vgg19.__name__: VGG19_Weights.DEFAULT,\n  models.inception_v3.__name__: Inception_V3_Weights.DEFAULT,\n}\n\n# Experiment around dropout & Learning Rate & different optimizer (Adam)\ndef init_model(name):\n  if not path.exists(RESULT_DIR):\n    os.mkdir(RESULT_DIR)\n\n  clean_vram()\n  seed_everything()\n  model = model_constructors[name](weights=model_weights[name])\n  \n  # fine-tune pretrain models to our usecase\n  # https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html#initialize-and-reshape-the-networks\n  NUM_CLASSES = len(class_names)\n  DROPOUT = 0.5\n  if name == models.alexnet.__name__ or name == models.vgg16.__name__ or name == models.vgg19.__name__:\n    num_ftrs = model.classifier[6].in_features\n    model.classifier[6] = nn.Linear(num_ftrs, NUM_CLASSES)\n#     model.classifier[6] = nn.Sequential(\n#       nn.Dropout(DROPOUT),\n#       nn.Linear(num_ftrs, NUM_CLASSES)\n#     )\n  elif name == models.densenet201.__name__:\n    num_ftrs = model.classifier.in_features\n    model.classifier = nn.Linear(num_ftrs, NUM_CLASSES)\n#     model.classifier = nn.Sequential(\n#       nn.Dropout(DROPOUT),\n#       nn.Linear(num_ftrs, NUM_CLASSES)\n#     )\n  elif name == models.squeezenet1_1.__name__:\n    model.classifier = nn.Conv2d(512, NUM_CLASSES, kernel_size=(1,1), stride=(1,1))\n#     model.classifier = nn.Sequential(\n#       nn.Dropout(DROPOUT),\n#       nn.Conv2d(512, NUM_CLASSES, kernel_size=(1,1), stride=(1,1))\n#     )\n    model.num_classes = NUM_CLASSES\n  elif name == models.inception_v3.__name__:\n    auxLogits_num_ftrs = model.AuxLogits.fc.in_features\n    model.AuxLogits.fc = nn.Linear(auxLogits_num_ftrs, NUM_CLASSES)\n#     model.AuxLogits.fc = nn.Sequential(\n#       nn.Dropout(DROPOUT),\n#       nn.Linear(auxLogits_num_ftrs, NUM_CLASSES)\n#     )\n    primary_num_ftrs = model.fc.in_features\n    model.fc = nn.Linear(primary_num_ftrs, NUM_CLASSES)\n#     model.fc = nn.Sequential(\n#       nn.Dropout(DROPOUT),\n#       nn.Linear(primary_num_ftrs, NUM_CLASSES)\n#     )\n  else:\n    # resnet, resnext & googlenet\n    num_ftrs = model.fc.in_features\n    model.fc= nn.Linear(num_ftrs, NUM_CLASSES)\n#     model.fc = nn.Sequential(\n#       nn.Dropout(DROPOUT),\n#       nn.Linear(num_ftrs, NUM_CLASSES)\n#     )\n\n  model = model.to(device)\n  criterion = nn.CrossEntropyLoss()\n  optimizer= optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n  exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n  if is_gpu_avail():\n    # Use Automatic Mixed Precision as an attempt to solve CUDA out of memory and to speed things up\n    # https://pytorch.org/tutorials/recipes/recipes/amp_recipe.html#all-together-automatic-mixed-precision\n    scaler = torch.cuda.amp.GradScaler()\n  else:\n    raise RuntimeError('This code only support machine with GPU.')\n\n  # print('=====================================')\n  print(f'{name} is initialized')\n  # print('=====================================')\n  # print(model)\n  return model, criterion, optimizer, scaler\n\n# https://pytorch.org/tutorials/beginner/saving_loading_models.html\n# https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html\ndef save_model(perf_metrics, model, optimizer, scaler, history, model_path):\n  torch.save({\n    'perf_metrics': perf_metrics,\n    'model_state_dict': model.state_dict(),\n    'optimizer_state_dict': optimizer.state_dict(),\n    \"scaler_state_dict\": scaler.state_dict(),\n    'history': history,\n    }, model_path)\n\ndef load_model(model, optimizer, scaler, model_path):\n  if not os.path.exists(model_path):\n    log_to_file(f\">>> WARN: {name_of_caller()}() model path '{model_path}' don't exist!\")\n    return None, model, optimizer, scaler, None, None\n  checkpoint = torch.load(model_path)\n  perf_metrics = checkpoint['perf_metrics']\n  model.load_state_dict(checkpoint['model_state_dict'])\n  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n  scaler.load_state_dict(checkpoint['scaler_state_dict'])\n  history = checkpoint['history']\n  total_epoch = len(history) - 1\n  del checkpoint\n\n  return perf_metrics, model, optimizer, scaler, history, total_epoch","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define Function to Train Models","metadata":{}},{"cell_type":"code","source":"# training and validation loops\ndef train(model,\n    criterion,\n    optimizer,\n    scaler,\n    train_dataloader,\n    valid_dataloader,\n    model_path,\n    max_epochs_stop=10,\n    n_epochs=400,\n    min_epoch=300,\n    print_every=1):\n    \n    epochs_no_improve = 0\n    perf = {\n        'best_epoch': 0,\n        'valid_loss_min': np.Inf,\n        'valid_best_acc': 0,\n    }\n    total_epoch = 0\n\n    try:\n        if os.path.exists(model_path):\n            perf, model, optimizer, scaler, history, total_epoch = load_model(model, optimizer, scaler, model_path)\n            log_to_file(f'Model has been trained for: {total_epoch} epochs.')\n            log_to_file(f\"Best epoch: {perf['best_epoch']} with loss: {perf['valid_loss_min']:.4f} and acc: {100 * perf['valid_best_acc']:.2f}%\\n\")\n        else:\n            history = []\n            log_to_file(f'Starting Training from Scratch.\\n')\n    except:\n        history = []\n        log_to_file(f'exception: start from scratch.\\n')\n\n    overall_start = time.time()\n    if total_epoch >= n_epochs:\n        log_to_file(f'Model has been fully trained. n_epochs specified is: {n_epochs} epochs.')\n        history = pd.DataFrame(\n            history,\n            columns=['train_loss', 'valid_loss','train_acc', 'valid_acc'])\n        return model, history, perf\n\n    seed_everything()\n\n    # Main loop - continue training on where we left off if there's a saved model\n    for epoch in range(total_epoch, n_epochs):\n        # keep track of training and validation loss each epoch\n        train_loss = 0.0\n        valid_loss = 0.0\n\n        train_acc = 0\n        valid_acc = 0\n\n        # Set to training\n        model.train()\n        start = time.time()\n        for ii, (data, target) in enumerate (train_dataloader):\n            data, target = data.cuda(), target.cuda()\n            optimizer.zero_grad()\n\n            # only for inception_v3 - https://discuss.pytorch.org/t/why-auxiliary-logits-set-to-false-in-train-mode/40705/15\n            with torch.cuda.amp.autocast():\n              # output, aux_output = model(data)\n              # loss1 = criterion(output, target)\n              # loss2 = criterion(aux_output, target)\n              # loss = loss1 + 0.4*loss2\n              output = model(data)\n              loss = criterion(output, target)\n            # loss.backward()\n            # optimizer.step()\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n\n            train_loss += loss.item() * data.size(0)\n            _, pred = torch.max(output, dim=1)\n            correct_tensor = pred.eq(target.data.view_as(pred))\n            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n            train_acc += accuracy.item() * data.size(0)\n            print(\n                f'Epoch: {epoch}\\t{100 * (ii + 1) / len(train_dataloader):.2f}% complete. {time.time() - start:.2f} seconds elapsed in epoch.', end=\"\\r\")\n            \n            # cleanup to save VRAM\n            del data, target\n#             clean_vram()\n\n        # After training loops ends, start validation\n        else:\n            print(\">>> Starting validation...\\n\")\n            with torch.no_grad():\n                model.eval()\n                for data, target in valid_dataloader:\n                    if is_gpu_avail():\n                        data, target = data.cuda(), target.cuda()\n                    output = model(data)\n                    loss = criterion(output, target)\n                    valid_loss += loss.item() * data.size(0)\n                    _, pred = torch.max(output, dim=1)\n                    correct_tensor = pred.eq(target.data.view_as(pred))\n                    accuracy = torch.mean(\n                        correct_tensor.type(torch.FloatTensor))\n                    valid_acc += accuracy.item() * data.size(0)\n                    \n                    # cleanup to save VRAM\n                    del data, target\n#                     clean_vram()\n                train_loss = train_loss / train_data_size\n                valid_loss = valid_loss / valid_data_size\n                train_acc = train_acc / train_data_size\n                valid_acc = valid_acc / valid_data_size\n                history.append([train_loss, valid_loss,train_acc, valid_acc])\n                if (epoch + 1) % print_every == 0:\n                    log_to_file(f'Epoch: {epoch}', True)\n                    log_to_file(\n                        f'Training Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}',\n                        True\n                    )\n                    log_to_file(\n                        f'Training Accuracy: {100 * train_acc:.2f}%\\t Validation Accuracy: {100 * valid_acc:.2f}% \\n',\n                        True\n                    )\n          \n                if valid_loss < perf['valid_loss_min']:\n                    print(f\">>> Saving model: valid_loss:{valid_loss}\\n\")\n                    epochs_no_improve = 0\n                    perf['best_epoch'] = epoch\n                    perf['valid_loss_min'] = valid_loss\n                    perf['valid_best_acc'] = valid_acc\n                    save_model(perf, model, optimizer, scaler, history, model_path)\n                else:\n                    print(f\">>> No improvement: valid_loss:{valid_loss}; epoch:{epoch}; epochs_no_improve:{epochs_no_improve}\\n\")\n                    epochs_no_improve += 1\n                    # Trigger early stopping\n                    if epoch > min_epoch and epochs_no_improve >= max_epochs_stop:\n                        log_to_file(\n                            f\"\\nEarly Stopping! Total epochs: {epoch}. Best epoch: {perf['best_epoch']} with loss: {perf['valid_loss_min']:.4f} and acc: {100 * perf['valid_best_acc']:.2f}%\"\n                        )\n                        total_time = time.time() - overall_start\n                        log_to_file(\n                            f'{total_time:.4f} total seconds elapsed. {total_time / (epoch+1):.4f} seconds per epoch.'\n                        )\n                        log_to_file()\n\n                        # Load the best state from saved model\n                        _, model, optimizer, scaler, _, _ = load_model(model, optimizer, scaler, model_path)\n                        # save the full history\n                        save_model(perf, model, optimizer, scaler, history, model_path)\n\n                        # Format history\n                        history = pd.DataFrame(\n                            history,\n                            columns=[\n                                'train_loss', 'valid_loss', 'train_acc',\n                                'valid_acc'\n                            ])\n                        return model, history, perf\n    \n    total_time = time.time() - overall_start\n    log_to_file(\n        f\"\\nBest epoch: {perf['best_epoch']} with loss: {perf['valid_loss_min']:.4f} and acc: {100 * perf['valid_best_acc']:.4f}%\"\n    )\n    log_to_file(\n        f\"{total_time:.4f} total seconds elapsed. {total_time / (perf['best_epoch']+1):.4f} seconds per epoch.\"\n    )\n    log_to_file()\n\n    # Load the best state from saved model\n    _, model, optimizer, scaler, _, _ = load_model(model, optimizer, scaler, model_path)\n    # save the full history\n    save_model(perf, model, optimizer, scaler, history, model_path)\n\n    # Format history\n    history = pd.DataFrame(\n        history,\n        columns=['train_loss', 'valid_loss','train_acc', 'valid_acc'])\n    \n    return model, history, perf\n\n\ndef save_train_val_loss_graph(history, perf):\n  plt.figure(figsize=(8, 6))\n  for c in ['train_loss', 'valid_loss']:\n      plt.plot(\n          history[c], label=c)\n\n  title = f'{curr_model} - Training and Validation Losses'\n  full_path = os.path.join(RESULT_DIR, f'{title}.png')\n  plt.xlabel('Epochs')\n  plt.ylabel('Average Losses')\n  plt.title(title)\n  plt.axvline(x=perf['best_epoch'], color='r', label='best_epoch')\n  plt.legend()\n  plt.savefig(full_path, bbox_inches='tight')\n\n\ndef save_train_val_acc_graph(history, perf):\n  plt.figure(figsize=(8, 6))\n  for c in ['train_acc', 'valid_acc']:\n      plt.plot(\n          100 * history[c], label=c)\n      \n  title = f'{curr_model} - Training and Validation Accuracy'\n  full_path = os.path.join(RESULT_DIR, f'{title}.png')\n  plt.xlabel('Epochs')\n  plt.ylabel('Average Accuracy')\n  plt.title(title)\n  plt.axvline(x=perf['best_epoch'], color='r', label='best_epoch')\n  plt.legend()\n  plt.savefig(full_path, bbox_inches='tight')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Define Functions to Visualize Prediction","metadata":{}},{"cell_type":"code","source":"# confusion matrix \ndef getConfusionMatrix(model, dataloader, is_test=False, show_image=False, print_to_console_only=False):\n    model.eval()\n    confusion_matrix=np.zeros((2,2),dtype=int)\n    num_images=test_data_size\n    \n    with torch.no_grad():\n        for i, (data,target) in enumerate(dataloader):\n            data = data.to(device)\n            target = target.to(device)\n            \n            output = model(data) \n            _, pred = torch.max(output, 1)\n            \n            for j in range(data.size()[0]): \n                if pred[j]==1 and target[j]==1:\n                    term='TP'\n                    confusion_matrix[0][0]+=1\n                elif pred[j]==1 and target[j]==0:\n                    term='FP'\n                    confusion_matrix[1][0]+=1\n                elif pred[j]==0 and target[j]==1:\n                    term='FN'\n                    confusion_matrix[0][1]+=1\n                elif pred[j]==0 and target[j]==0:\n                    term='TN'\n                    confusion_matrix[1][1]+=1\n            \n                if show_image:\n                    log_to_file(f'predicted: {class_names[pred[j]]}', print_to_console_only)\n                    log_to_file(term, print_to_console_only)\n                    imshow(data.cpu().data[j])\n        \n        log_to_file(None, print_to_console_only)\n        category = 'Test' if is_test else 'Validation'\n        log_to_file('=====================', print_to_console_only)\n        log_to_file(f'{category} Results ', print_to_console_only)\n        log_to_file('=====================', print_to_console_only)\n        log_to_file('Confusion Matrix: ', print_to_console_only)\n        log_to_file(np.array2string(confusion_matrix), print_to_console_only)\n        log_to_file(None, print_to_console_only)\n\n        log_to_file(f'Sensitivity: {100*confusion_matrix[0][0]/(confusion_matrix[0][0]+confusion_matrix[0][1])}', print_to_console_only)\n        log_to_file(f'Specificity: {100*confusion_matrix[1][1]/(confusion_matrix[1][1]+confusion_matrix[1][0])}', print_to_console_only)\n        log_to_file(f'PPV: {100*confusion_matrix[0][0]/(confusion_matrix[0][0]+confusion_matrix[1][0])}', print_to_console_only)\n        log_to_file(f'NPV: {100*confusion_matrix[1][1]/(confusion_matrix[1][1]+confusion_matrix[0][1])}', print_to_console_only)\n        log_to_file(f'Accuracy: {100*(confusion_matrix[0][0]+confusion_matrix[1][1])/(confusion_matrix[0][0]+confusion_matrix[0][1]+confusion_matrix[1][1]+confusion_matrix[1][0])}', print_to_console_only)\n        log_to_file(f'F1-Score: {(2*confusion_matrix[0][0])/(2*confusion_matrix[0][0]+confusion_matrix[1][0]+confusion_matrix[0][1])}', print_to_console_only)\n        log_to_file(None, print_to_console_only)\n    return confusion_matrix\n\n\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n\ndef save_test_acc_n_loss_graph(model, dataloader, criterion):\n  pass\n  # NOT NEEDED YET\n  # with torch.no_grad():\n  #   model.eval()\n  #   for data, target in dataloader:\n  #       if is_gpu_avail():\n  #           data, target = data.cuda(), target.cuda()\n  #       output = model(data)\n  #       loss = criterion(output, target)\n  #       test_loss += loss.item() * data.size(0)\n  #       _, pred = torch.max(output, dim=1)\n  #       correct_tensor = pred.eq(target.data.view_as(pred))\n  #       accuracy = torch.mean(\n  #           correct_tensor.type(torch.FloatTensor))\n  #       test_acc += accuracy.item() * data.size(0)\n  #   train_loss = train_loss / train_data_size\n  #   test_loss = test_loss / test_data_size\n  #   train_acc = train_acc / train_data_size\n  #   test_acc = test_acc / test_data_size\n\n\n# def visualize_test_prediction(model):\n#   covid_test_img_dir = '/content/drive/My Drive/data/test/covid/'\n#   img_list = [Image.open(os.path.join(pth, f)).convert('RGB')\n#       for pth, dirs, files in os.walk(covid_test_img_dir) for f in files]\n\n#   # test_img_paths = ['/content/drive/My Drive/data/test/covid/2020.02.22.20024927-p19-68%3.png',\n#   #                         '/content/drive/My Drive/data/test/covid/2020.02.22.20024927-p19-68%4.png',\n#   #                         '/content/drive/My Drive/data/test/covid/2020.02.22.20024927-p19-68%5.png']\n#   # img_list = [Image.open( img_path) for img_path in test_img_paths]\n\n#   # log_to_file(img_list)\n\n#   test_batch = torch.stack([image_transforms['test'](img).to(device)\n#                               for img in img_list])\n#   pred_logits_tensor = model(test_batch)\n#   pred_probs = F.softmax(pred_logits_tensor, dim=1).cpu().data.numpy()\n\n#   row = 12\n#   col = 3\n#   fig, axs = plt.subplots(row, col, figsize=(20, 50))\n#   r = 0\n#   c = 0\n#   for i, img in enumerate(img_list):\n#       if c >= col:\n#         r += 1\n#         c = 0\n#       ax = axs[r, c]\n#       ax.axis('off')\n#       ax.set_title(\"{:.4f}% Covid, {:.4f}% NonCovid\".format(100*pred_probs[i,0],\n#                                                               100*pred_probs[i,1]))\n#       ax.imshow(img)\n#       c +=1\n\n#   title = f'{curr_model} - Covid Image Prediction'\n#   full_path = os.path.join(RESULT_DIR, f'{title}.png')\n#   plt.savefig(full_path, bbox_inches='tight')\n\n\ndef getPredProbs(model, datasetStr, count, isSeeded=True):\n  if isSeeded:\n    seed_everything()\n  \n  dataset = data[datasetStr].samples\n  img_list = []\n  for i, (img_path, cls_idx) in enumerate(dataset):\n    if i >= count:\n      break\n    img_list.append(Image.open(img_path).convert('RGB'))\n\n  test_batch = torch.stack([image_transforms[datasetStr](img).to(device)\n                              for img in img_list])\n  pred_logits_tensor = model(test_batch)\n  return F.softmax(pred_logits_tensor, dim=1).cpu().data.numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Run all models - Init Models + Training","metadata":{}},{"cell_type":"code","source":"model_list = [\n    models.alexnet.__name__, # 0\n    models.squeezenet1_1.__name__, #1\n    models.resnet50.__name__, # 2\n    models.resnet101.__name__, # 3\n    models.resnet152.__name__, # 4\n    models.resnext101_32x8d.__name__, # 5\n    models.densenet201.__name__, # 6\n    models.googlenet.__name__, # 7\n    models.vgg16.__name__, # 8\n    models.vgg19.__name__, #9\n    models.inception_v3.__name__, #10\n]\n\nfor i in range(0,11):\n  # https://github.com/pytorch/pytorch/issues/50198\n  # skipped these because cannot use deterministic algorithm\n#   skip_model = [0, 1, 5, 8, 9, 10]\n  skip_model = [0, 1, 2, 3, 5, 6, 7, 8, 9, 10]\n  if i in skip_model:\n    continue\n  curr_model = model_list[i]\n\n  # Initialize model, criterion and optimizer\n  model, criterion, optimizer, scaler = init_model(curr_model)\n\n#   Training & Validation\n  model, history, perf = train(\n      model,\n      criterion,\n      optimizer,\n      scaler,\n      train_loader,\n      val_loader,\n      model_path=f'{path.join(RESULT_DIR, curr_model)}.pt',\n      max_epochs_stop=5,  # Early stopping intialization\n      n_epochs=5,\n      min_epoch=5,\n      print_every=10)\n\n  save_train_val_loss_graph(history, perf)\n  save_train_val_acc_graph(history, perf)\n  getConfusionMatrix(model, val_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Out of memory issue\n\n- References\n    - https://discuss.pytorch.org/t/using-main-ram-instead-of-vram/59344/3 \n    - https://duckduckgo.com/?q=pytorch+colab+use+system+ram+instead+of+gpu+ram&ia=web\n    - https://stackoverflow.com/questions/59129812/how-to-avoid-cuda-out-of-memory-in-pytorch\n        - [CUDA Out of Memory discussion in kaggle forum](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/discussion/91081)\n    - https://pytorch.org/docs/stable/notes/cuda.html#memory-management\n    - [trick to debug tensor memory](https://forum.pyro.ai/t/a-trick-to-debug-tensor-memory/556)\n- The fix\n    - Delete unused tensor, force garbage collection and run `empty_cache()`\n    - Set PYTORCH_CUDA_ALLOC_CONF to `max_split_size_mb:512`. This prevents the allocator to split block large than 512MB\n    - [mixed precision training & delete checkpoint](https://medium.com/deep-learning-for-protein-design/a-comprehensive-guide-to-memory-usage-in-pytorch-b9b7c78031d3)","metadata":{}},{"cell_type":"code","source":"torch.cuda.memory_stats(device)\n# print(torch.cuda.memory_summary(device))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}