# -*- coding: utf-8 -*-
"""Serena.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/187Z04CNQBVV3jmCdA2sSbMTs9BB40qh_

# CT Scan Training
---

## Overview
1. Import the libraries
2. Get the image from Google Drive
3. Load dataset
4. Load model
5. Train
6. Visualise Prediction using Test Images

---

## Dataset Preparation
1. Training folder with 2 sub folders (exp: Covid and Non) 
    - the no. of subfolders depends on how many classes u have, sub-folder name must same with the class names
2. Validation folder with 2 subfolders ---- same to training folder 
3. Testing folder with 2 subfolders ---- same to training folder
---

## Step 1 - Import the libraries
Import useful libraries to be used in later steps.
"""

# Commented out IPython magic to ensure Python compatibility.
from __future__ import print_function, division
import torch
import torch.nn as nn
from torch import optim, cuda
import torch.optim as optim
from torch.optim import lr_scheduler
import numpy as np
import torchvision
from torchvision import datasets, models, transforms
import matplotlib.pyplot as plt
import time
import os
import copy
import torch.nn.functional as F
from timeit import Timer
import pandas as pd  
from PIL import Image
from mlxtend.plotting import plot_confusion_matrix
from timeit import default_timer as timer
from google.colab import drive
import random

plt.ion()   # interactive mode
# ensure reproducibility across different executions
# https://pytorch.org/docs/stable/notes/randomness.html
# https://www.kaggle.com/mlwhiz/third-place-model-for-toxic-comments-in-pytorch
# https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html
def seed_everything(seed=18):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
torch.backends.cudnn.benchmark = False
torch.backends.cudnn.deterministic = True
#torch.set_deterministic(True)
torch.use_deterministic_algorithms(True)
# %env CUBLAS_WORKSPACE_CONFIG=:4096:8

"""## Step 2 - Get the image from Google Drive"""

drive.mount('/content/drive')
data_dir = '/content/drive/My Drive/data'
ori_train_dir = os.path.join(data_dir, 'train')
ori_valid_dir = os.path.join(data_dir, 'test') # purposely switch val and test due to early wrong usage of them
ori_test_dir = os.path.join(data_dir, 'val')
result_dir = os.path.join(data_dir, 'result')

curr_model = ""
def log_to_file(txt=None, print_to_console_only=False):
  if txt is None:
    txt = ''
  txt += '\n'
  print(txt)
  if print_to_console_only:
    return
  full_path = os.path.join(result_dir, f'{curr_model}.txt')
  with open(full_path, mode='a') as f:
    f.write(txt)

"""# Step 2.5 - Create More Images using Augmentation"""

from pathlib import Path

aug_data_dir = os.path.join(data_dir, 'analysis')
train_dir = os.path.join(aug_data_dir, 'train')
valid_dir = os.path.join(aug_data_dir, 'val')
test_dir = os.path.join(aug_data_dir, 'test')

duplicate_img_transforms = {
  'colorJitter': transforms.Compose([
      transforms.Resize(size=256),
      transforms.CenterCrop(size=224),
      transforms.ColorJitter(brightness=.5, hue=.3),
      transforms.ToTensor()
  ]),
  'perspective': transforms.Compose([
      transforms.Resize(size=256),
      transforms.CenterCrop(size=224),
      transforms.RandomPerspective(distortion_scale=0.4, p=1.0),
      transforms.ToTensor()
  ]),
  'rotation': transforms.Compose([
      transforms.Resize(size=256),
      transforms.CenterCrop(size=224),
      transforms.RandomRotation(degrees=(30, 70)),
      transforms.ToTensor()
  ]),
  'scaleNmove': transforms.Compose([
      transforms.Resize(size=256),
      transforms.CenterCrop(size=224),
      transforms.RandomAffine(degrees=(0, 0), translate=(0.05, 0.2), scale=(0.7, 0.85)),
      transforms.ToTensor()
  ]),
  'hflip': transforms.Compose([
      transforms.Resize(size=256),
      transforms.CenterCrop(size=224),
      transforms.RandomHorizontalFlip(p=1),
      transforms.ToTensor()
  ]),
  'vflip': transforms.Compose([
      transforms.Resize(size=256),
      transforms.CenterCrop(size=224),
      transforms.RandomVerticalFlip(p=1),
      transforms.ToTensor()
  ])
}

# https://gist.github.com/andrewjong/6b02ff237533b3b2c554701fb53d5c4d
class ImageFolderWithPath(datasets.ImageFolder):
    """Custom dataset that includes image file paths. Extends
    torchvision.datasets.ImageFolder
    """  
    def __getitem__(self, index):
        original_tuple = super(ImageFolderWithPath, self).__getitem__(index)
        path = self.imgs[index][0]
        tuple_with_path = (original_tuple + (path,))
        return tuple_with_path

class ImageFolderWithCustomClassOrder(datasets.ImageFolder):
    """Custom dataset that sort class in reverse alphabetical order. Extends
    torchvision.datasets.ImageFolder
    """  
    def find_classes(self, directory):
      classes = sorted((entry.name for entry in os.scandir(directory) if entry.is_dir()), reverse=True)
      if not classes:
          raise FileNotFoundError(f"Couldn't find any class folder in {directory}.")

      class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}
      return classes, class_to_idx

def create_more_dataset():
  for trans_type in duplicate_img_transforms:
    imgData = {
      'train': ImageFolderWithPath(ori_train_dir, duplicate_img_transforms[trans_type]),
      'valid': ImageFolderWithPath(ori_valid_dir, duplicate_img_transforms[trans_type]),
      'test': ImageFolderWithPath(ori_test_dir, duplicate_img_transforms[trans_type])
    }

    for data_type in imgData:
      for i, (img, cls, ori_path) in enumerate(imgData[data_type]):
        _, file_extension = os.path.splitext(ori_path)
        imgname = f'{i}_{trans_type}{file_extension}'

        classStr = imgData[data_type].classes[cls]
        img_file_path = os.path.join(train_dir, classStr, imgname)
        if data_type is 'valid':
          img_file_path = os.path.join(valid_dir, classStr, imgname)
        elif data_type is 'test':
          img_file_path = os.path.join(test_dir, classStr, imgname)

        torchvision.utils.save_image(img, img_file_path)

# seed_everything()
# create_more_dataset()

"""## Step 3 - Load dataset
1. The image data is separated as below
```
80% - train (covid first then non covid)
10% - validation (covid first then non covid)
10% - test (random)
```
2. The covid and noncovid are separated into its own folders in each the train, val & test folders.
3. The `torch` data loader will automatically categorized the images into classes based on it's folder
4. Resize is compulsory in order to standardise the images.
5. Horizontal flip, rotation is to create more variation of the dataset, to prevent overfitting.
"""

seed_everything()
image_transforms = {
    # 'train': transforms.Compose([
    #     transforms.RandomHorizontalFlip(),
    #     transforms.RandomRotation(30),
    #     transforms.RandomResizedCrop(224), 
    #     transforms.ToTensor(),
    #     transforms.Normalize([0.485, 0.456, 0.406],
    #                          [0.229, 0.224, 0.225])
    # ]),
    'train': transforms.Compose([
        # no need to resize anymore as it is done in the img generation step
        # https://pytorch.org/vision/master/auto_examples/plot_transforms.html#autoaugment
        transforms.AutoAugment(transforms.AutoAugmentPolicy.IMAGENET),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
    ]),
    'cam': transforms.Compose([
        transforms.Resize(size=256), # 321
        transforms.CenterCrop(size=224), # 299
        transforms.AutoAugment(transforms.AutoAugmentPolicy.IMAGENET),
        transforms.ToTensor(),
    ])
}


# Creating DataSet objects that "hold" our images
data={
  'train':ImageFolderWithCustomClassOrder(train_dir,image_transforms['train']),
  'val': ImageFolderWithCustomClassOrder(valid_dir,image_transforms['val']),
  'test' : ImageFolderWithCustomClassOrder(test_dir,image_transforms['test']),
  'cam' : ImageFolderWithPath(valid_dir,image_transforms['cam']),
}
# dataset size
train_data_size = len(data['train'])
valid_data_size = len(data['val'])
test_data_size = len(data['test'])

# Creating DataLoader objects that let us work with our images in batches
train_dataloader = torch.utils.data.DataLoader(data['train'],batch_size=64,shuffle=True)
valid_dataloader  = torch.utils.data.DataLoader(data['val'],batch_size=64,shuffle=True)
test_dataloader  = torch.utils.data.DataLoader(data['test'],batch_size=64,shuffle=True)
cam_dataloader  = torch.utils.data.DataLoader(data['cam'],batch_size=1,shuffle=True)

class_names = data['train'].classes
print(class_names)
print(data['train'].class_to_idx)

# using gpu or else cpu
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
train_on_gpu = cuda.is_available()
print(f'Train on gpu: {train_on_gpu}')
print(f'train size:{train_data_size}; validation size:{valid_data_size}; test size:{test_data_size}')

"""### Step 3.5 - Visualize the train dataloader"""

def imshow(inp, title=None):
    inp = inp.numpy().transpose((1, 2, 0))
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    inp = std * inp + mean
    inp = np.clip(inp, 0, 1)
    plt.imshow(inp)
    if title is not None:
        plt.title(title)
    plt.pause(0.001)  # pause a bit so that plots are updated
# data, classes = next(iter(train_dataloader))
# out = torchvision.utils.make_grid(data)
# imshow(out, title=[class_names[x] for x in classes])

"""## Step 4 - Initialize Pretrained Model"""

model_constructors = {
  models.alexnet.__name__: models.alexnet, 
  models.squeezenet1_1.__name__: models.squeezenet1_1,
  models.resnet50.__name__: models.resnet50, 
  models.resnet101.__name__: models.resnet101,
  models.resnet152.__name__: models.resnet152, 
  models.resnext101_32x8d.__name__: models.resnext101_32x8d, 
  models.densenet201.__name__: models.densenet201, 
  models.googlenet.__name__: models.googlenet, 
  models.vgg16.__name__: models.vgg16, 
  models.vgg19.__name__: models.vgg19, 
  models.inception_v3.__name__: models.inception_v3, 
}

# Experiment around dropout & Learning Rate & different optimizer (Adam)
def init_model(name):
  seed_everything()
  model = model_constructors[name](pretrained=True) 
  
  # fine-tune pretrain models to our usecase
  # https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html#initialize-and-reshape-the-networks
  NUM_CLASSES = len(class_names)
  if name == models.alexnet.__name__ or name == models.vgg16.__name__ or name == models.vgg19.__name__:
    num_ftrs = model.classifier[6].in_features
    model.classifier[6] = nn.Linear(num_ftrs, NUM_CLASSES) 
  elif name == models.densenet201.__name__:
    num_ftrs = model.classifier.in_features
    model.classifier = nn.Linear(num_ftrs, NUM_CLASSES)
  elif name == models.squeezenet1_1.__name__:
    model.classifier = nn.Conv2d(512, NUM_CLASSES, kernel_size=(1,1), stride=(1,1))
    model.num_classes = NUM_CLASSES
  elif name == models.inception_v3.__name__:
    auxLogits_num_ftrs = model.AuxLogits.fc.in_features
    model.AuxLogits.fc = nn.Linear(auxLogits_num_ftrs, NUM_CLASSES)
    primary_num_ftrs = model.fc.in_features
    model.fc = nn.Linear(primary_num_ftrs, NUM_CLASSES)
  else:
    # resnet, resnext & googlenet
    num_ftrs = model.fc.in_features
    model.fc= nn.Linear(num_ftrs, 2) 
  
  model = model.to(device)
  criterion = nn.CrossEntropyLoss()
  optimizer= optim.SGD(model.parameters(), lr=0.1, momentum=0.9)
  exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)
  if train_on_gpu:
    model = model.to('cuda')
    # Use Automatic Mixed Precision as an attempt to solve CUDA out of memory and to speed things up
    # https://pytorch.org/tutorials/recipes/recipes/amp_recipe.html#all-together-automatic-mixed-precision
    scaler = torch.cuda.amp.GradScaler()
  else:
    raise RuntimeError('This code only support machine with GPU.')

  # print('=====================================')
  print(f'{name} is initialized')
  # print('=====================================')
  # print(model)
  return model, criterion, optimizer, scaler

# https://pytorch.org/tutorials/beginner/saving_loading_models.html
# https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html
def save_model(perf_metrics, model, optimizer, scaler, history, model_path):
  torch.save({
    'perf_metrics': perf_metrics,
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    "scaler_state_dict": scaler.state_dict(),
    'history': history,
    }, model_path)

def load_model(model, optimizer, scaler, model_path):
  checkpoint = torch.load(model_path)
  perf_metrics = checkpoint['perf_metrics']
  model.load_state_dict(checkpoint['model_state_dict'])
  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
  scaler.load_state_dict(checkpoint['scaler_state_dict'])
  history = checkpoint['history']
  total_epoch = len(history) - 1

  return perf_metrics, model, optimizer, scaler, history, total_epoch

"""## Step 5 - Train Model"""

# training and validation loops
def train(model,
    criterion,
    optimizer,
    scaler,
    train_dataloader,
    valid_dataloader,
    model_path,
    max_epochs_stop=10,
    n_epochs=400,
    min_epoch=300,
    print_every=1):
    
    epochs_no_improve = 0
    perf = {
        'best_epoch': 0,
        'valid_loss_min': np.Inf,
        'valid_best_acc': 0,
    }
    total_epoch = 0

    try:
        if os.path.exists(model_path):
            perf, model, optimizer, scaler, history, total_epoch = load_model(model, optimizer, scaler, model_path)
            log_to_file(f'Model has been trained for: {total_epoch} epochs.')
            log_to_file(f"Best epoch: {perf['best_epoch']} with loss: {perf['valid_loss_min']:.4f} and acc: {100 * perf['valid_best_acc']:.2f}%\n")
        else:
            history = []
            log_to_file(f'Starting Training from Scratch.\n')
    except:
        history = []
        log_to_file(f'exception: start from scratch.\n')

    overall_start = time.time()
    if total_epoch >= n_epochs:
        log_to_file(f'Model has been fully trained. n_epochs specified is: {n_epochs} epochs.')
        history = pd.DataFrame(
            history,
            columns=['train_loss', 'valid_loss','train_acc', 'valid_acc'])
        return model, history, perf

    seed_everything()

    # Main loop - continue training on where we left off if there's a saved model
    for epoch in range(total_epoch, n_epochs):
        # keep track of training and validation loss each epoch
        train_loss = 0.0
        valid_loss = 0.0

        train_acc = 0
        valid_acc = 0

        # Set to training
        model.train()
        start = time.time()
        for ii, (data, target) in enumerate (train_dataloader):
            data, target = data.cuda(), target.cuda()
            optimizer.zero_grad()

            # only for inception_v3 - https://discuss.pytorch.org/t/why-auxiliary-logits-set-to-false-in-train-mode/40705/15
            with torch.cuda.amp.autocast():
              # output, aux_output = model(data)
              # loss1 = criterion(output, target)
              # loss2 = criterion(aux_output, target)
              # loss = loss1 + 0.4*loss2
              output = model(data)
              loss = criterion(output, target)
            # loss.backward()
            # optimizer.step()
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()

            train_loss += loss.item() * data.size(0)
            _, pred = torch.max(output, dim=1)
            correct_tensor = pred.eq(target.data.view_as(pred))
            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))
            train_acc += accuracy.item() * data.size(0)
            print(
                f'Epoch: {epoch}\t{100 * (ii + 1) / len(train_dataloader):.2f}% complete. {time.time() - start:.2f} seconds elapsed in epoch.', end="\r")

        # After training loops ends, start validation
        else:
            with torch.no_grad():
                model.eval()
                for data, target in valid_dataloader:
                    if train_on_gpu:
                        data, target = data.cuda(), target.cuda()
                    output = model(data)
                    loss = criterion(output, target)
                    valid_loss += loss.item() * data.size(0)
                    _, pred = torch.max(output, dim=1)
                    correct_tensor = pred.eq(target.data.view_as(pred))
                    accuracy = torch.mean(
                        correct_tensor.type(torch.FloatTensor))
                    valid_acc += accuracy.item() * data.size(0)
                train_loss = train_loss / train_data_size
                valid_loss = valid_loss / valid_data_size
                train_acc = train_acc / train_data_size
                valid_acc = valid_acc / valid_data_size
                history.append([train_loss, valid_loss,train_acc, valid_acc])
                if (epoch + 1) % print_every == 0:
                    log_to_file(f'Epoch: {epoch}', True)
                    log_to_file(
                        f'Training Loss: {train_loss:.4f} \tValidation Loss: {valid_loss:.4f}',
                        True
                    )
                    log_to_file(
                        f'Training Accuracy: {100 * train_acc:.2f}%\t Validation Accuracy: {100 * valid_acc:.2f}% \n',
                        True
                    )
          
                if valid_loss < perf['valid_loss_min']:
                    epochs_no_improve = 0
                    perf['best_epoch'] = epoch
                    perf['valid_loss_min'] = valid_loss
                    perf['valid_best_acc'] = valid_acc
                    save_model(perf, model, optimizer, scaler, history, model_path)
                else:
                    epochs_no_improve += 1
                    # Trigger early stopping
                    if epoch > min_epoch and epochs_no_improve >= max_epochs_stop:
                        log_to_file(
                            f"\nEarly Stopping! Total epochs: {epoch}. Best epoch: {perf['best_epoch']} with loss: {perf['valid_loss_min']:.4f} and acc: {100 * perf['valid_best_acc']:.2f}%"
                        )
                        total_time = time.time() - overall_start
                        log_to_file(
                            f'{total_time:.4f} total seconds elapsed. {total_time / (epoch+1):.4f} seconds per epoch.'
                        )
                        log_to_file()

                        # Load the best state from saved model
                        _, model, optimizer, scaler, _, _ = load_model(model, optimizer, scaler, model_path)
                        # save the full history
                        save_model(perf, model, optimizer, scaler, history, model_path)

                        # Format history
                        history = pd.DataFrame(
                            history,
                            columns=[
                                'train_loss', 'valid_loss', 'train_acc',
                                'valid_acc'
                            ])
                        return model, history, perf

    total_time = time.time() - overall_start
    log_to_file(
        f"\nBest epoch: {perf['best_epoch']} with loss: {perf['valid_loss_min']:.4f} and acc: {100 * perf['valid_best_acc']:.4f}%"
    )
    log_to_file(
        f"{total_time:.4f} total seconds elapsed. {total_time / (perf['best_epoch']+1):.4f} seconds per epoch."
    )
    log_to_file()

    # Load the best state from saved model
    _, model, optimizer, scaler, _, _ = load_model(model, optimizer, scaler, model_path)
    # save the full history
    save_model(perf, model, optimizer, scaler, history, model_path)

    # Format history
    history = pd.DataFrame(
        history,
        columns=['train_loss', 'valid_loss','train_acc', 'valid_acc'])
    
    return model, history, perf

def save_train_val_loss_graph(history, perf):
  plt.figure(figsize=(8, 6))
  for c in ['train_loss', 'valid_loss']:
      plt.plot(
          history[c], label=c)

  title = f'{curr_model} - Training and Validation Losses'
  full_path = os.path.join(result_dir, f'{title}.png')
  plt.xlabel('Epochs')
  plt.ylabel('Average Losses')
  plt.title(title)
  plt.axvline(x=perf['best_epoch'], color='r', label='best_epoch')
  plt.legend()
  plt.savefig(full_path, bbox_inches='tight')

def save_train_val_acc_graph(history, perf):
  plt.figure(figsize=(8, 6))
  for c in ['train_acc', 'valid_acc']:
      plt.plot(
          100 * history[c], label=c)
      
  title = f'{curr_model} - Training and Validation Accuracy'
  full_path = os.path.join(result_dir, f'{title}.png')
  plt.xlabel('Epochs')
  plt.ylabel('Average Accuracy')
  plt.title(title)
  plt.axvline(x=perf['best_epoch'], color='r', label='best_epoch')
  plt.legend()
  plt.savefig(full_path, bbox_inches='tight')

"""
## Step 6 - Visualize Prediction using Validation Images

Confusion Matrix is used to quantify the quality of the model predictions. These numbers are then used to compare between different sets of hyperparameters to get the best model possible.

Finally, the chosen model is then use to classify the test images"""

# confusion matrix 
def getConfusionMatrix(model, dataloader, is_test=False, show_image=False, print_to_console_only=False):
    model.eval()
    confusion_matrix=np.zeros((2,2),dtype=int)
    num_images=test_data_size
    
    with torch.no_grad():
        for i, (data,target) in enumerate(dataloader):
            data = data.to(device)
            target = target.to(device)
            
            output = model(data) 
            _, pred = torch.max(output, 1)
            
            for j in range(data.size()[0]): 
                if pred[j]==1 and target[j]==1:
                    term='TP'
                    confusion_matrix[0][0]+=1
                elif pred[j]==1 and target[j]==0:
                    term='FP'
                    confusion_matrix[1][0]+=1
                elif pred[j]==0 and target[j]==1:
                    term='FN'
                    confusion_matrix[0][1]+=1
                elif pred[j]==0 and target[j]==0:
                    term='TN'
                    confusion_matrix[1][1]+=1
            
                if show_image:
                    log_to_file(f'predicted: {class_names[pred[j]]}', print_to_console_only)
                    log_to_file(term, print_to_console_only)
                    imshow(data.cpu().data[j])
        
        log_to_file(None, print_to_console_only)
        category = 'Test' if is_test else 'Validation'
        log_to_file('=====================', print_to_console_only)
        log_to_file(f'{category} Results ', print_to_console_only)
        log_to_file('=====================', print_to_console_only)
        log_to_file('Confusion Matrix: ', print_to_console_only)
        log_to_file(np.array2string(confusion_matrix), print_to_console_only)
        log_to_file(None, print_to_console_only)

        log_to_file(f'Sensitivity: {100*confusion_matrix[0][0]/(confusion_matrix[0][0]+confusion_matrix[0][1])}', print_to_console_only)
        log_to_file(f'Specificity: {100*confusion_matrix[1][1]/(confusion_matrix[1][1]+confusion_matrix[1][0])}', print_to_console_only)
        log_to_file(f'PPV: {100*confusion_matrix[0][0]/(confusion_matrix[0][0]+confusion_matrix[1][0])}', print_to_console_only)
        log_to_file(f'NPV: {100*confusion_matrix[1][1]/(confusion_matrix[1][1]+confusion_matrix[0][1])}', print_to_console_only)
        log_to_file(f'Accuracy: {100*(confusion_matrix[0][0]+confusion_matrix[1][1])/(confusion_matrix[0][0]+confusion_matrix[0][1]+confusion_matrix[1][1]+confusion_matrix[1][0])}', print_to_console_only)
        log_to_file(f'F1-Score: {(2*confusion_matrix[0][0])/(2*confusion_matrix[0][0]+confusion_matrix[1][0]+confusion_matrix[0][1])}', print_to_console_only)
        log_to_file(None, print_to_console_only)
    return confusion_matrix

def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)

def save_test_acc_n_loss_graph(model, dataloader, criterion):
  pass
  # NOT NEEDED
  # with torch.no_grad():
  #   model.eval()
  #   for data, target in dataloader:
  #       if train_on_gpu:
  #           data, target = data.cuda(), target.cuda()
  #       output = model(data)
  #       loss = criterion(output, target)
  #       test_loss += loss.item() * data.size(0)
  #       _, pred = torch.max(output, dim=1)
  #       correct_tensor = pred.eq(target.data.view_as(pred))
  #       accuracy = torch.mean(
  #           correct_tensor.type(torch.FloatTensor))
  #       test_acc += accuracy.item() * data.size(0)
  #   train_loss = train_loss / train_data_size
  #   test_loss = test_loss / test_data_size
  #   train_acc = train_acc / train_data_size
  #   test_acc = test_acc / test_data_size

def visualize_test_prediction(model):
  covid_test_img_dir = '/content/drive/My Drive/data/test/covid/'
  img_list = [Image.open(os.path.join(pth, f)).convert('RGB')
      for pth, dirs, files in os.walk(covid_test_img_dir) for f in files]

  # test_img_paths = ['/content/drive/My Drive/data/test/covid/2020.02.22.20024927-p19-68%3.png',
  #                         '/content/drive/My Drive/data/test/covid/2020.02.22.20024927-p19-68%4.png',
  #                         '/content/drive/My Drive/data/test/covid/2020.02.22.20024927-p19-68%5.png']
  # img_list = [Image.open( img_path) for img_path in test_img_paths]

  # log_to_file(img_list)

  test_batch = torch.stack([image_transforms['test'](img).to(device)
                              for img in img_list])
  pred_logits_tensor = model(test_batch)
  pred_probs = F.softmax(pred_logits_tensor, dim=1).cpu().data.numpy()

  row = 12
  col = 3
  fig, axs = plt.subplots(row, col, figsize=(20, 50))
  r = 0
  c = 0
  for i, img in enumerate(img_list):
      if c >= col:
        r += 1
        c = 0
      ax = axs[r, c]
      ax.axis('off')
      ax.set_title("{:.4f}% Covid, {:.4f}% NonCovid".format(100*pred_probs[i,0],
                                                              100*pred_probs[i,1]))
      ax.imshow(img)
      c +=1

  title = f'{curr_model} - Covid Image Prediction'
  full_path = os.path.join(result_dir, f'{title}.png')
  plt.savefig(full_path, bbox_inches='tight')

def getPredProbs(model, datasetStr, count, isSeeded=True):
  if isSeeded:
    seed_everything()
  
  dataset = data[datasetStr].samples
  img_list = []
  for i, (img_path, cls_idx) in enumerate(dataset):
    if i >= count:
      break
    img_list.append(Image.open(img_path).convert('RGB'))

  test_batch = torch.stack([image_transforms[datasetStr](img).to(device)
                              for img in img_list])
  pred_logits_tensor = model(test_batch)
  return F.softmax(pred_logits_tensor, dim=1).cpu().data.numpy()

"""## Step 7 - Run all models - Init Models + Training"""

model_list = [
    models.alexnet.__name__, # 0
    models.squeezenet1_1.__name__, #1
    models.resnet50.__name__, # 2
    models.resnet101.__name__, # 3
    models.resnet152.__name__, # 4
    models.resnext101_32x8d.__name__, # 5
    models.densenet201.__name__, # 6
    models.googlenet.__name__, # 7
    models.vgg16.__name__, # 8
    models.vgg19.__name__, #9
    models.inception_v3.__name__, #10
]

for i in range(0,11):
  # https://github.com/pytorch/pytorch/issues/50198
  # skipped these because cannot use deterministic algorithm
  skip_model = [0, 1, 5, 8, 9, 10]
  if i in skip_model:
    continue
  curr_model = model_list[i]

  # Initialize model, criterion and optimizer
  model, criterion, optimizer, scaler = init_model(curr_model)

  # Training & Validation
  model, history, perf = train(
      model,
      criterion,
      optimizer,
      scaler,
      train_dataloader,
      valid_dataloader,
      model_path=f'/content/drive/My Drive/data/{curr_model}.pt',
      max_epochs_stop=5,  # Early stopping intialization
      n_epochs=300,
      min_epoch=300,
      print_every=10)

  save_train_val_loss_graph(history, perf)
  save_train_val_acc_graph(history, perf)
  getConfusionMatrix(model, valid_dataloader)

"""# Step 8 - Analysis

## Test Phase

- After selecting the best hyperparameters and models, use the model to predict the result on the test images
- Get the confusion matrix and prediction similar to what we did for validation images
"""

def reloadModel():
  saved_model_path = f'/content/drive/My Drive/data/{curr_model}.pt'
  if os.path.exists(saved_model_path):
    model, criterion, optimizer, scaler = init_model(curr_model)
    return load_model(model, optimizer, scaler, saved_model_path)
  else:
    return None, None, None, None, None, None

from torchvision.transforms.functional import normalize, resize, to_tensor, to_pil_image

def show_transformed_images(dataset_type):
  col = 5
  row = 2
  fig, axs = plt.subplots(row, col, figsize=(4, 4))
  plt.subplots_adjust(left=0.1, bottom=0.1, right=4, top=4, wspace=0.1, hspace=0.05)
  r = 0
  c = 0
  for i, (img, cls) in enumerate(data[dataset_type]):
    if i >= row*col:
      break

    # Display it
    if c >= col:
      r += 1
      c = 0
    # ax = axs[r]
    ax = axs[r, c]
    ax.axis('off')
    # https://pillow.readthedocs.io/en/stable/reference/ImageOps.html?highlight=grayscale#PIL.ImageOps.grayscale
    ax.imshow(to_pil_image(img, mode='RGB'))
    c += 1

# show_transformed_images('cam')

model_list = [
    models.alexnet.__name__, # 0
    models.squeezenet1_1.__name__, #1
    models.resnet50.__name__, # 2
    models.resnet101.__name__, # 3
    models.resnet152.__name__, # 4
    models.resnext101_32x8d.__name__, # 5
    models.densenet201.__name__, # 6
    models.googlenet.__name__, # 7
    models.vgg16.__name__, # 8
    models.vgg19.__name__, #9
    models.inception_v3.__name__, #10
]

for i in range(0,11):
  skip_model = [0, 1, 8, 9, 10]
  if i in skip_model:
    continue
  curr_model = model_list[i]
  _, model, _, _, _, _ = reloadModel()
  seed_everything()
  if model:
    trainable_parameters = count_parameters(model)
    print(f'model: {curr_model}, number of trainable parameters: {trainable_parameters}')

# curr_model = models.alexnet.__name__
# getConfusionMatrix(model, test_dataloader, True)
# visualize_test_prediction(model)

"""## GradCam Step:

### References
  - This repo is used instead due to much better support with pytorch - https://github.com/frgfm/torch-cam
  - [This reference](https://github.com/jacobgil/pytorch-grad-cam) is obselete as need to find the layer manually, and facing `IndexError: index 2 is out of bounds for dimension 1 with size 2`

### Chosing the Target Layer (Obselete)
You need to choose the target layer to compute CAM for. Some common choices are:

- Resnet18 and 50: `model.layer4[-1]`
- VGG and densenet161: `model.features[-1]`
- mnasnet1_0: `model.layers[-1]`
- ViT: `model.blocks[-1].norm1`
- SwinT: `model.layers[-1].blocks[-1].norm1`
"""

# !pip install torchcam
!pip install git+https://github.com/frgfm/torch-cam.git#egg=torchcam
from torchvision.io.image import read_image
from torchvision.transforms.functional import normalize, resize, to_tensor, to_pil_image
from torchcam.cams import SmoothGradCAMpp
from torchcam.utils import overlay_mask
from PIL import ImageOps
from mpl_toolkits.axes_grid1 import ImageGrid
import math

""" 
Class activation explorer using TorchCAM.
Iterate through validation database and overlay images with class activation 
heatmap.

Reference: https://github.com/frgfm/torch-cam 
"""
def runGradCam():
  _, model, _, _, _, _ = reloadModel()
  if model:
    model.eval()
    cam_extractor = SmoothGradCAMpp(model)

    DATASET_TYPE = 'cam'
    num_iter = 2
    pred_probs = getPredProbs(model, DATASET_TYPE, num_iter)

    seed_everything()
    # NOTE: file path is only valid if dataset type is cam
    for i, (img, cls, ori_path) in enumerate(data[DATASET_TYPE]):
      if i >= num_iter:
        break
      
      img = img.to(device)
      # Preprocess your data and feed it to the model
      out = model(img.unsqueeze(0))
      # Retrieve the CAM by passing the class index and the model output
      activation_map = cam_extractor(cls, out)

      # Resize the CAM and overlay it
      # https://matplotlib.org/stable/tutorials/colors/colormaps.html#miscellaneous
      ori_img = to_pil_image(img)
      result = overlay_mask(ori_img, to_pil_image(activation_map, mode='F'), colormap='jet', alpha=0.5)

      # Display it
      # https://matplotlib.org/stable/gallery/axes_grid1/simple_axesgrid.html
      fig = plt.figure(figsize=(20., 20.))
      grid = ImageGrid(fig, 111,  # similar to subplot(111)
                      nrows_ncols=(1, 2),  # creates 1x2 grid of axes
                      axes_pad=0.1,  # pad between axes in inch.
                      )
      for ax, im in zip(grid, [ori_img, result]):
        # Iterating over the grid returns the Axes.
        classStr = data[DATASET_TYPE].classes[cls]
        ax.set_title("{:.4f}% Covid, \n{:.4f}% NonCovid, Actual:{}, ImagePath:{}".format(100*pred_probs[i,0],
                                                                      100*pred_probs[i,1],
                                                                      classStr, ori_path), fontsize=10)
        ax.imshow(im)
      title = f'{curr_model} - GradCam++ Visualization'
      full_path = os.path.join(result_dir, f'{title}.png')
      plt.savefig(full_path)
      plt.show()

curr_model = models.resnext101_32x8d.__name__
runGradCam()
# try:
  
# except Exception as e:
#     print(e)
# except RuntimeError as e:
#     print(e)
# else:
#     print('No exception')

"""# Re-Analysis Step: 
Run Model Performance Evaluation by Loading from Saved Model

## Archive - Old code
"""

# curr_model = models.alexnet.__name__
# saved_model_path = f'/content/drive/My Drive/data/{curr_model}.pt'
# if os.path.exists(saved_model_path):
#   # Initialize model, criterion and optimizer
#   model, criterion, optimizer, scaler = init_model(curr_model)
#   perf, model, optimizer, scaler, history, total_epoch = load_model(model, optimizer, scaler, saved_model_path)

#   print(
#       f"\nBest epoch: {perf['best_epoch']} with loss: {perf['valid_loss_min']:.4f} and acc: {100 * perf['valid_best_acc']:.4f}%"
#   )
#   history = pd.DataFrame(
#               history,
#               columns=[
#                   'train_loss', 'valid_loss', 'train_acc',
#                   'valid_acc'
#               ])
#   save_train_val_loss_graph(history, perf)
#   save_train_val_acc_graph(history, perf)
  # getConfusionMatrix(model, valid_dataloader, False, True)

def oldRunGradCamV1(model):
  !pip install grad-cam
  !pip install ttach
  from pytorch_grad_cam import GradCAM, GradCAMPlusPlus
  from pytorch_grad_cam.utils.image import show_cam_on_image
  from torchsummary import summary
  
  target_layer = model.fc

  covid_test_img_dir = '/content/drive/My Drive/data/test/covid/'
  img_list = [Image.open(os.path.join(pth, f)).convert('RGB')
      for pth, dirs, files in os.walk(covid_test_img_dir) for f in files]
  test_batch = torch.stack([image_transforms['test'](img).to(device)
                              for img in img_list])
  input_tensor = model(test_batch) # Create an input tensor image for your model..
  # Note: input_tensor can be a batch tensor with several images!

  # Construct the CAM object once, and then re-use it on many images:
  cam = GradCAM(model=model, target_layer=target_layer, use_cuda=True)

  # If target_category is None, the highest scoring category
  # will be used for every image in the batch.
  # target_category can also be an integer, or a list of different integers
  # for every image in the batch.
  target_category = None

  # You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.
  grayscale_cam = cam(input_tensor=input_tensor, target_category=target_category)

  pred_probs = F.softmax(input_tensor, dim=1).cpu().data.numpy()
  row = 12
  col = 3
  fig, axs = plt.subplots(row, col, figsize=(20, 50))
  r = 0
  c = 0
  for i, img in enumerate(img_list):
    single_cam = grayscale_cam[i]
    composite_img = show_cam_on_image(img, single_cam)

    if c >= col:
      r += 1
      c = 0
    ax = axs[r, c]
    ax.axis('off')
    ax.set_title("{:.4f}% Covid, {:.4f}% NonCovid".format(100*pred_probs[i,0],
                                                            100*pred_probs[i,1]))
    ax.imshow(composite_img)
    c +=1

  title = f'{curr_model} - GradCam++ Visualization'
  full_path = os.path.join(result_dir, f'{title}.png')
  plt.savefig(full_path, bbox_inches='tight')

def oldRunGradCamV2():
  _, model, _, _, _, _ = reloadModel()
  if model:
    model.eval()
    cam_extractor = SmoothGradCAMpp(model)
    
    DATASET_TYPE = 'cam'
    pred_probs = getPredProbs(model, DATASET_TYPE)
    col = 3
    # row = 2
    row = math.ceil(len(data['cam'])/col)
    fig, axs = plt.subplots(row, col, figsize=(4, 4))
    plt.subplots_adjust(left=0.1, bottom=0.1, right=4, top=4, wspace=0.1, hspace=2)
    r = 0
    c = 0
    for i, (img, cls) in enumerate(data[DATASET_TYPE]):
      if i >= row*col:
        break
      img = img.to(device)
      # img = read_image(img_path)
      # Preprocess it for your chosen model
      # input_tensor = normalize(resize(img, (224, 224)) / 255., [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])

      # Preprocess your data and feed it to the model
      out = model(img.unsqueeze(0))
      # Retrieve the CAM by passing the class index and the model output
      activation_map = cam_extractor(cls, out)

      # Visualize the raw CAM
      # plt.imshow(activation_map.numpy()); plt.axis('off'); plt.tight_layout(); plt.show()

      # Resize the CAM and overlay it
      # https://matplotlib.org/stable/tutorials/colors/colormaps.html#miscellaneous
      result = overlay_mask(to_pil_image(img), to_pil_image(activation_map, mode='F'), colormap='jet', alpha=0.5)

      # Display it
      if c >= col:
        r += 1
        c = 0
      # ax = axs[r]
      ax = axs[r, c]
      ax.axis('off')
      ax.locator_params(tight=True)
      classStr = "Covid"
      if cls:
        classStr = "NonCovid"
      ax.set_title("{:.4f}% Covid, \n{:.4f}% NonCovid, Actual:{}".format(100*pred_probs[i,0],
                                                                    100*pred_probs[i,1],
                                                                    classStr), fontsize=8)
      ax.imshow(result)
      c += 1

    # https://matplotlib.org/stable/tutorials/intermediate/tight_layout_guide.html
    # plt.tight_layout(pad=10, h_pad=10)
    title = f'{curr_model} - GradCam++ Visualization'
    full_path = os.path.join(result_dir, f'{title}.png')
    plt.savefig(full_path)

# Investigating data structure of imageloader and dataloader 
# val_data = data['val']
# print(val_data.samples)
print(len(data['cam']))

# val_loader = torch.utils.data.DataLoader(val_data,batch_size=None)
# for i_batch, sample_batched in enumerate(val_loader):
#   print(f'{i_batch}: {len(sample_batched)}')